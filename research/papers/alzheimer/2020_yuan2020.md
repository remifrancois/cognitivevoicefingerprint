# Yuan2020 et al. (2020) — Full Text Extraction

**Source file:** 2020_yuan2020.pdf
**Pages:** 24
**Extracted by:** MemoVoice research pipeline (PyMuPDF)

---

## Full Paper Content

Prepared for submission to JHEP
Operator complexity: a journey to the edge of Krylov
space
E. Rabinovici,a A. S´anchez-Garrido,b R. Shira and J. Sonnerb
aRacah Institute of Physics, The Hebrew University, Jerusalem 9190401, Israel
bDepartment of Theoretical Physics, University of Geneva, 24 quai Ernest-Ansermet, 1214 Gen`eve
4, Switzerland
E-mail: eliezer@mail.huji.ac.il, Adrian.SanchezGarrido@unige.ch,
ruth.shir@mail.huji.ac.il, Julian.Sonner@unige.ch
Abstract: Heisenberg time evolution under a chaotic many-body Hamiltonian H trans-
forms an initially simple operator into an increasingly complex one, as it spreads over
Hilbert space. Krylov complexity, or ‘K-complexity’, quantiﬁes this growth with respect
to a special basis, generated by H by successive nested commutators with the operator. In
this work we study the evolution of K-complexity in ﬁnite-entropy systems for time scales
greater than the scrambling time ts > log(S). We prove rigorous bounds on K-complexity
as well as the associated Lanczos sequence and, using reﬁned parallelized algorithms, we
undertake a detailed numerical study of these quantities in the SYK4 model, which is max-
imally chaotic, and compare the results with the SYK2 model, which is integrable. While
the former saturates the bound, the latter stays exponentially below it. We discuss to what
extent this is a generic feature distinguishing between chaotic vs. integrable systems.
arXiv:2009.01862v2  [hep-th]  22 Jun 2021


---

Contents
1
Introduction
1
2
Time evolution of operators and physical properties of Krylov space
3
3
Integrable systems and SYK2
6
4
Lanczos algorithm
7
5
K-complexity and K-entropy
8
6
Numerical results
9
7
Discussion
12
A Lanczos sequence in RMT
15
B Krylov space for SYK2
16
C Numerical algorithms
17
C.1
Full Orthogonalization (FO)
18
C.2
Partial Re-Orthogonalization (PRO)
18
1
Introduction
The concepts of state and operator complexity lie at the intersection of quantum informa-
tion, condensed matter physics, quantum ﬁeld theory (QFT) and black hole physics. One is
thus faced with a diversity of concepts and methods on how to precisely deﬁne and actually
measure complexity. The identiﬁcation of very large time scales in black hole physics and
corresponding phenomena in QFT (via the AdS/CFT correspondence) [1–8] has motivated
the search for a form of complexity whose time dependence has the following distinctive
characteristics: In fast-scrambling systems with ﬁnite entropy S, complexity should grow
exponentially in time until ts ∼log(S) (known as the scrambling time) when it reaches
a value of order O(S); it then switches to a linear-in-time behavior until times of order
exp(O(S)) when it settles around a plateau of order exp(O(S)); ﬁnally, after times of order
exp(exp(O(S))) it is expected to start performing the Poincar´e dance. The growth of the
Einstein-Rosen bridge was connected in [4] with complexity growth of the quantum state in
the dual CFT. A notion of complexity known as Krylov complexity, or K-complexity, was
introduced in [9] as a useful diagnostic of quantum chaos in the thermodynamic limit. In
[10] it was argued for the ﬁrst time that K-complexity of generic operators in ﬁnite-size sys-
tems exhibits the proﬁle of complexity described above. This paper reports on a complete
– 1 –


---

numerical analysis of K-complexity for all time scales, including scrambling and well be-
yond, in concrete models demonstrating the above-described time-dependence. This is the
ﬁrst time that such large time scales are studied with numerical methods, and in concrete
models. We uncover non-perturbative eﬀects which were not initially anticipated. The
study overcame known numerical instabilities and employed powerful algorithms executed
on large computing clusters.
Roughly speaking the time evolution of complexity quantiﬁes how quickly a reference
operator grows under Heisenberg evolution in a pre-deﬁned basis. K-complexity, denoted
CK, measures this growth with respect to the Krylov basis which, as we shall see below,
is well-adapted to capture Heisenberg evolution eﬃciently. K-complexity depends on the
Hamiltonian of the system and a chosen reference operator. It has an advantage over other
notions of complexity: its deﬁnition doesn’t require an arbitrary tolerance parameter.
For circuit complexity 1, to cite but one example, such a tolerance parameter must be
introduced, and its presence is crucial in establishing its boundedness [13–15], whereas
K-complexity is naturally bounded from above 2 [10]. It is known to be bounded by the
dimension of the Hilbert space of operators; below we prove a stronger bound.
CK provides a ﬁne-grained notion of complexity, as it manifestly distinguishes all lin-
early independent operators up to a given, ﬁxed length. These features make K-complexity
a natural choice for quantifying the evolution of operators at late times (see e.g. Sec. 2.1
in [17] for a careful deﬁnition of chaotic time scales) which is this paper’s focus.
In studying K-complexity at these time scales one should either explicitly construct,
or obtain bounds on, the full sequence of Lanczos coeﬃcients, bn, which characterize the
Krylov basis of an operator. These coeﬃcients arise in the process of orthonormalizing3
the Krylov basis [18, 19]. In [9] it was hypothesized that in a chaotic quantum system
in the thermodynamic limit, the Lanczos coeﬃcients grow at a linear rate. In [10] it was
suggested that, in ﬁnite chaotic systems, the Lanczos-sequence could exhibit plateau-like
features over a certain range. The study of ﬁnite chaotic systems reported in this paper
constructs the full Lanczos sequence to reveal a non-perturbative decay of this plateau,
making an initially small but eventually persistent correction to the “cliﬀ-ended plateau”
conjectured in [10]. We refer to the resulting proﬁle as “the Descent”.
We study K-complexity in the maximally chaotic SYK4 model [20–23], which is by
now well-established as a toy model displaying key chaotic properties of black holes, in-
cluding late-time spectral chaos [7, 24]. We also study the quadratic SYK2 model, which
is integrable, showing Poisson statistics [25–27].
The structure of this paper is as follows: In Section 2 we describe the Krylov space
and an analytical upper bound on its dimension.
In Section 3 we discuss the Krylov
1Circuit complexity of the SYK4 model, the main work-horse of this paper, has previously been studied
in [11, 12].
2Operator size complexity [16] shares this advantage of not requiring a tolerance parameter, but diﬀers
from CK in other crucial respects. For example, it is directly bounded by the total system size, while the
upper bound for K-complexity scales exponentially with system size.
3The process of orthonormalization requires a choice of inner product. In this work we use the standard
Frobenius inner-product (see Section 4). For other choices of inner product inherited from ﬁnite-temperature
correlation functions see discussions in [9, 18].
– 2 –


---

space dimension for integrable systems, focusing on SYK2. In Section 4 the Lanczos algo-
rithm by which an orthonormal basis for Krylov space as well as the Lanczos-sequence are
constructed, is described. In Section 5 we present the deﬁnitions of K-complexity and K-
entropy as well as expectations for their saturation values. Section 6 shows our numerical
results for the Lanczos-sequences, K-complexity and K-entropy for complex SYK4 systems
with 8, 9 and 10 fermions. In Section 7 we summarize the main points of our results, remark
on some of the diﬀerences between K-complexity and circuit complexity and on possible
holographic aspects. Appendix A presents numerical results for the Lanczos-sequence in
Random Matrix Theory. Appendix B discusses the Krylov basis for SYK2 and Appendix
C shows explicitly the numerical algorithms used to produce the data in the paper.
2
Time evolution of operators and physical properties of Krylov space
We begin by providing the deﬁnition of Krylov space and stressing its relation to the
structure of the spectrum of the system under consideration (and hence to its integrable or
chaotic character). Consider a Hilbert space H, of dimension dim (H) = D, with associated
Hilbert space of linear operators L (H) ≡b
H, acting on H and satisfying dim( b
H) = D2.
Now consider a system whose dynamics are described by a certain (hermitian) Hamiltonian
H ∈b
H, and an observable O ∈b
H.
The associated Krylov space [28] is deﬁned as the minimal subspace of operator space
that contains the time evolution of O at all times.
The time evolution of O is given by
O(t) = eiHtOe−iHt = eiLtO
(2.1)
where the Liouvillian operator is deﬁned as L ≡[H, ·]. Thus the Krylov space is the linear
span of all nested commutators of the Hamiltonian with the operator:
HO = span {LnO}+∞
n=0 = span {O, [H, O], [H, [H, O]], . . . } .
(2.2)
Equivalently, HO is the minimal invariant subspace of the Liouvillian that contains O. We
denote dim (HO) ≡K.
K is determined by studying the cardinality of the maximal set of linearly independent
objects of the form LnO, which can be found by computing the rank of

O, LO, L2O, . . . LnO, . . .
T
,
(2.3)
in a convenient matrix representation, which we now deﬁne.
Let us choose the basis
|ωab) ≡|Ea⟩⟨Eb|, on b
H, which is naturally induced by the eigenbasis of the Hamiltonian
on H. Then each nested commutator takes the form:
Ln |O) = δn0
D
X
a=1
Oaa|ωaa) +
D
X
a,b=1
a̸=b
Oab ωn
ab |ωab)
(2.4)
– 3 –


---

where we have deﬁned the phases 4 ωab := Ea −Eb, which are eigenvalues of the Liouvillian
acting on |ωab). Note that the ω’s related to pairs of the form (a, a) are zero, ωaa = 0 for
all a = 1, ..., D. Displaying the coordinates of (2.4) as rows one can construct a matrix
representation of (2.3), which turns out to be a Vandermonde matrix. The rank of this
matrix is at most D2, as it has D2 columns, so we shall keep the same number of rows to
make it a square Vandermonde matrix:








O11 O22 . . . ODD
O12
O13
. . .
OD−1,D
0
0
. . .
0
O12 ω12
O13 ω13
. . . OD−1,D ωD−1,D
0
0
. . .
0
O12 ω2
12
O13 ω2
13
. . . OD−1,D ω2
D−1,D
...
...
...
...
...
...
...
...
0
0
. . .
0
O12 ωD2−1
12
O13 ωD2−1
13
. . . OD−1,D ωD2−1
D−1,D








.
(2.5)
To ﬁnd its actual rank, we can compute its determinant, which is given by:
∆({ωab})
D
Y
i,j=1
Oij ,
(2.6)
where ∆({ωab}) is the Vandermonde determinant of the phases in the matrix. The expres-
sion (2.6) will be zero if any of the phases are degenerate, and also if any of the matrix
elements in the energy basis vanish, so the corresponding columns should be removed in
order to be left with a matrix of maximal rank. Hence, the Krylov dimension K can be
estimated using the following algorithmic prescription: K is equal to the number of dis-
tinct phases corresponding to the indices of non-zero matrix elements of the operator in the
energy basis. The zero phase ωaa = 0 is always at least D times degenerate and therefore,
since it can only be counted once, the Krylov dimension is bounded by:
1 ≤K ≤D2 −D + 1
(2.7)
for any non-vanishing operator.
In general, if the operator O has a non-vanishing projection over several eigenstates of
the Liouvillian that share the same degenerate eigenvalue, then this phase only contributes
one dimension to the Krylov space. So a legitimate question is to wonder what particular
linear combination of those eigenstates is actually contained in the Krylov space. In order
to answer this, one can consider the form of the operator Ln |O) given in (2.4). Suppose
that, for some set I of pairs of indices, the eigenvalue is degenerate:
L |ωab) = ω |ωab)
∀(a, b) ∈I
(2.8)
i.e. ωab = ω for all (a, b) ∈I. Assume also that ωab ̸= ω for any (a, b) /∈I. Inserting (2.8)
in (2.4) one ﬁnds:
LnO = ωn X
(a,b)∈I
Oab |ωab) +
X
(a,b)/∈I
Oab ωn
ab |ωab) .
(2.9)
4We shall refer to energy diﬀerences as phases, since they appear as such in the moment expansion of
the two-point function of O.
– 4 –


---

It is manifest now that the direction of the ω-eigenspace that contributes to the Krylov
space is precisely the projection of the operator O over such an eigenspace:
|Kω) :=
X
(a,b)∈I
Oab |ωab) .
(2.10)
Let‘s call |Kω) the eigenspace representative for the phase ω. The structure of the Krylov
space is now fully understood: Each eigenspace of the Liouvillian over which the operator
O has a non-vanishing projection contributes one Krylov dimension, through a linear com-
bination of the basis of the eigenspace of the form (2.10). We can thus redeﬁne the Krylov
space as:
HO = span {|Kω) ,
ω ∈σ(L)}
(2.11)
where σ(L) denotes the spectrum of L. Finally, the Krylov dimension K is simply equal
to the number of non-zero eigenspace representatives |Kω).
For instance, if one considers a system whose Liouvillian has a spectrum with no
degeneracies (other than the unavoidable null phases) and an operator that is dense in the
energy basis, the Krylov dimension will be maximal, K = D2 −D + 1. The only source
of degeneracy in the phases will be the universal one due to diagonal phases ωaa = 0. We
can now note explicitly that the part of the operator algebra that is left out of the Krylov
space belongs to the space subtended by the projectors on the energy eigenstates, since
those correspond to zero phases, and the only combination of them that contributes to HO
is the representative of the ω = 0 eigenspace, in this case:
|K0) =
D
X
a=1
Oaa |ωaa) =
D
X
a=1
Oaa |Ea⟩⟨Ea| ≡
D
X
a=1
OaaPa.
(2.12)
To summarize, K is determined by exploiting the advantages of the basis in operator
space induced by the eigenbasis of the Hamiltonian; crucially, the determinant of a suitable
matrix containing the representation of these nested commutators in the given basis reduces
to a Vandermonde determinant of energy diﬀerences. The following algorithmic prescrip-
tion is derived: K is equal to the number of eigenspaces of the Liouvillian over which O
has non-zero projection. The eigenvalues of the Liouvillian are precisely all possible energy
diﬀerences, ωab = Ea −Eb. The zero phase is always at least D times degenerate, thus the
Krylov dimension is bounded by (2.7), for any non-zero operator. The more degeneracies
there are in the spectrum of the Liouvillian, the lower will be the Krylov dimension. The
expectation is that the spectrum of a chaotic system will not feature degeneracies apart
from those induced by the presence of extra symmetries; we therefore conjecture that typi-
cal 5 operators in chaotic systems saturate the upper bound in (2.7); for integrable systems
5Along the lines of ETH [29–32], we expect typical observables in chaotic systems to be dense in the
energy basis (as is the case of localized operators in local chaotic systems). Regardless of the structure of
the spectrum, one can always choose a ﬁne-tuned operator having a sparse matrix representation in the
energy basis, e.g. an eigenspace projector |E⟩⟨E|; such a candidate will indeed have a very small associated
Krylov space, but won’t generally fulﬁl the requirements to be considered a typical operator. Conserved
charges are also special operators, since they commute with the Hamiltonian, and therefore their Krylov
space is always one-dimensional.
– 5 –


---

we expect K to be signiﬁcantly smaller than the bound. We have conﬁrmed both expec-
tations by studying the chaotic SYK4 model (see numerics below) as well as RMT (see
Appendix A), and the integrable SYK2 model, see Section 3 below.
3
Integrable systems and SYK2
We have conjectured that the Krylov space for the time evolution of a typical operator
for integrable systems will be signiﬁcantly smaller than the upper bound in (2.7). Before
verifying our conjecture in the case of SYK2, we verify it in the simpler example of the
quantum harmonic oscillator H = ω(a†a+1/2) with the position operator ˆx =
q
1
2ω(a+a†),
for which the Krylov space dimension is K = 2, even though the Hilbert space is inﬁnite6. In
this case, the smallness of the Krylov space is due to the fact that the position operator has
a non-vanishing projection over only two eigenspaces of the Liouvillian (those corresponding
to the energy diﬀerences ω and −ω).
We now test our conjecture in SYK2, an integrable system with more structure than
the harmonic oscillator. For simplicity, let us use the Majorana (real) version of the model
[21, 23]:
H = i
X
1≤i<j≤L
mij χiχj
(3.1)
where the coupling strength mij ∈R is antisymmetric, mij = −mji, and each indepen-
dent matrix element is drawn from a Gaussian distribution with zero mean and variance
E(m2
ij) = m2/L. The number of sites is even, L = 2M, and the Majorana fermions satisfy
the relations {χi, χj} = δij,
χi = χ†
i.
The key point in the SYK2 case is the fact that operators do not grow after commu-
tation with the Hamiltonian, as also observed by [16, 33]. Hence the subspace containing
their time evolution will be, at most, that subtended by operators of ﬁxed equal size.
For example if the operator of study is a Majorana on some site with index A, O ≡χA,
commutation with the Hamiltonian will give [χiχj, χA] = δAjχi −δAiχj, which is again a
single-site operator (more details on the construction of the Krylov space in this case are
given in Appendix B). For one-site operators, this implies an upper bound on K:
K ≤L ∼log D ≪D2 −D + 1 .
(3.2)
It should be possible to reach this conclusion by studying the degeneracy structure of
the spectrum of SYK2, which features Poisson level spacing statistics, and it is natural
to expect other integrable systems to have a small Krylov space, due to the expected
degeneracies in the spectrum of the Liouvillian and to the sparseness of simple operators
in the energy basis. In general, interacting integrable systems feature Poisson level spacing
statistics, implying, at least, the existence of quasi-degenerate levels in the spectrum of
the Hamiltonian, and therefore also in that of the Liouvillian. We expect these systems to
behave as if the degeneracies were exact to a good degree of approximation, hence admitting
6Accordingly, the Lanczos-sequence contains a single element b1 = ω (see next section for the deﬁnition
of the Lanczos-sequence).
– 6 –


---

a description in terms of an eﬀectively smaller Krylov space. This argument applies, and
accounts for a signiﬁcant eﬀective reduction of Krylov space, even if the operator is not
sparse in the energy basis, as long as the invariant subspace of the Liouvillian over which it
has a non-trivial projection contains degenerate or quasi-degenerate levels. All this leads us
to suggest that integrable systems have a lower eﬀective Krylov dimension compared with
chaotic ones. As a ﬁrst step in trying to elevate this conjecture based on a few concrete
examples as well as qualitative ones, we estimate the minimal length of time for which the
diﬀerence in the dimension of the explored Krylov space is large. Since quasi-degenerate
energy levels are separated by less than the mean level spacing ∆∼Γe−S, where Γ is
a relevant energy scale of the system such as the total spectral width, we can estimate
the lowest time scale until which the Krylov dimensions of chaotic vs. integrable (with
quasi-degeneracies) systems remain signiﬁcantly diﬀerent, to be of order of the Heisenberg
time, i.e of order eO(S). For inﬁnite systems this lasts forever, while for large ﬁnite systems
this is way above the thermalization or scrambling time scales.
The question of what
ultimately generically happens between the Heisenberg time scale and the Poincar´e time
scale requires further research. To our knowledge, bounds like (2.7) and (3.2) haven’t been
noted previously in the literature.
4
Lanczos algorithm
Once the Krylov space adapted to time evolution of an operator with a constant Hamilto-
nian is identiﬁed, one would like to construct an orthonormal basis for it, given a certain
scalar product (·|·) on operator space. This is achieved with the Lanczos algorithm, which
is a particularization of the Gram-Schmidt procedure:
1. set b0 ≡0 and |O−1) ≡0
2. |O0) =
1
√
(O|O) |O)
3. for n ≥1: |An) = L |On−1) −bn−1 |On−2)
4. set bn =
p
(An|An)
5. if bn = 0 stop; otherwise set |On) =
1
bn |An) and go to step 3.
In this work we make use of the Frobenius product (A|B) = 1
DTr

A†B

. The algorithm
will construct an orthonormal set {On}K−1
n=0 , the Krylov basis, and the Lanczos coeﬃcients
{bn}K−1
n=1 .
Each Lanczos step produces an element |An) orthogonal to all previous |Om) with
m < n, so it is either zero or a new direction in Krylov space. For n < K, |An) ̸= 0
because the set that is being orthogonalized with this procedure has rank K (in particular,
|An) contains terms with up to n nested commutators of H with O). However, |AK) is
orthogonal to {On}K−1
n=0 , which is already a complete orthonormal basis of HO, so it must
therefore vanish, just as bK =
p
(AK|AK) = 0. We conclude that the Lanczos algorithm
must terminate by hitting a zero once all directions in Krylov space have been exhausted.
This is accounted for in Step 5 above.
– 7 –


---

The representation of the Liouvillian over the Krylov space in such a basis simpliﬁes to
a tridiagonal matrix (Om| L |On) = Tmn, whose entries are given by the Lanczos coeﬃcients:
T =











0 b1 0
0
. . .
0
b1 0 b2
0
. . .
0
0 b2 0
b3
. . .
0
...
...
...
...
...
bK−1
0 0
0 . . . bK−1
0











.
(4.1)
The eigenvalues of this matrix are all non-degenerate, and given precisely by the phases
corresponding to the eigenspaces of the Liouvillian that span the Krylov space (see Section
2).
The original Lanczos algorithm described above is known to suﬀer from numerical
instabilities which can be overcome using the re-orthogonalization algorithms FO and PRO
[34, 35] described in Appendix C.
5
K-complexity and K-entropy
Using the sequence of Lanczos coeﬃcients (which we will also call the b-sequence), one can
reduce the analysis of the time-evolution of an operator O into the solution of a diﬀerential
recurrence equation. The time-evolving operator can be expanded in the Krylov basis as:
|O(t)) =
K−1
X
n=0
inϕn(t) |On) ,
(5.1)
where ϕn(t) are time-dependent coeﬃcients which describe how the operator is distributed
over the Krylov basis (they may be thought of as the “wavefunctions” in n). Given the
Heisenberg equation dO
dt = i[H, O], they satisfy the diﬀerential recurrence equation
˙ϕn(t) = bnϕn−1(t) −bn+1ϕn+1 .
(5.2)
Here, ϕn(0) = δn0, since for a normalized operator O(0) = O0. We set ϕ−1(t) ≡0 in order
to make the recurrence (5.2) consistent with the deﬁnition (5.1).
Also, from unitarity
PK−1
n=0 |ϕn(t)|2 = 1.
The Lanczos coeﬃcients {bn}K−1
n=1 can be understood as hopping
amplitudes for the initial operator O0 to explore the “Krylov chain” and the functions
ϕn(t) can be visualized as wave-packets travelling on it [9].
We now display two quantities which highlight broad features of the distribution ϕn(t),
viz.
• K-complexity, which computes the average position of the distribution on the or-
dered Krylov basis:
CK(t) =
K−1
X
n=0
n|ϕn(t)|2.
(5.3)
– 8 –


---

• K-entropy, which computes how randomized the distribution is:
SK(t) = −
K−1
X
n=0
|ϕn(t)|2 log |ϕn(t)|2.
(5.4)
Assuming that at very late times the operator is evenly distributed over Krylov space,
there exists a saturation time tsat for which
|ϕ(t ≥tsat)|2 ∼1
K .
(5.5)
We can then get a rough estimate for the values of K-complexity and K-entropy at very
late times by plugging (5.5) into the formulas for CK(t) and SK(t):
CK(t ≥tsat) ∼1
K
K(K −1)
2
∼K
2 ,
(5.6)
SK(t ≥tsat) ∼−K 1
K log(1/K) = log(K).
(5.7)
Since for chaotic systems K ∼D2 and in general D ∼eS, where S is the entropy of the
system (in the sense of “log of the number of states”), we ﬁnd that the saturation value
of K-Entropy is essentially of order S, while the saturation value of K-complexity is of
order e2S. If CK(t) grows linearly after scrambling, the saturation time will be roughly
tsat ≡tK ∼e2S, in agreement with the expectation in [10]. These properties are conﬁrmed
in our numerical results.
6
Numerical results
In the following we present numerical results for complex SYK4, whose Hamiltonian is
schematically given by:
H =
X
ijkl
Jij;klc†
ic†
jckcl
(6.1)
where i, j, k, l = 1, 2, ..., L (L is the system size). Jij;kl is a complex matrix whose indepen-
dent elements follow normal distributions with:
Jij;kl = 0,
|Jij;kl|2 = 6J2
L3
(6.2)
where the overline denotes average over random realizations. It is worth recalling that the
Hilbert space of real (Majorana) SYK with L sites scales as 2L/2, while in the complex case
it scales as 2L. However, the advantage of using this version of SYK [36] lies in the fact
that the total number operator bn := PL
i=1 c†
ici commutes with the Hamiltonian, allowing
us to work in sectors of the Hilbert space with ﬁxed occupation number, denoted by N
(eigenvalue of bn). For our numerical computations we will take N =
 L
2

.
The (hermitian) observable chosen for numerical computations is the hopping operator
between sites L and L −1:
O = c†
L−1cL + c†
LcL−1 ≡hL−1,L .
(6.3)
– 9 –


---

Figure 1. Lanczos-sequence for L = 10. Left: “The Descent” depicted with linear scale along the
horizontal axis. After initial growth up to n ∼S, a slow decrease to zero with roughly constant
negative non-perturbative slope of order ∼−1
K ∼−e−2S. Fitted slope (in red) of the decaying part
is −2.21 · 10−5 ≈−1.58 · 10−5 = −K−1. On a 1:1 scale, the horizontal axis should be at least 843
meters long. Right: Logarithmic scale along the horizontal axis makes visible the initial ascent.
Figure 2. K-complexity averaged over 5 random realizations with L = 10 sites at half ﬁlling. Left:
Full time range computed. Saturation occurs at time scales of order tK ∼K ∼e2S with value near
K/2 = 31626.5 (this is the time scale at which the wave-packet ϕn(t), which propagates at roughly
constant – but slowly decreasing – velocity, reaches the edge of the Krylov chain). Right: Zoom
in at early times. Note the initial non-linear growth transforming into linear growth, as veriﬁed by
the linear ﬁt (in red). Relevant time scales are indicated in the plots, although their exact location
may depend on a dimensionful prefactor (the Lyapunov exponent, as discussed in [10]).
Any other hopping operator hij should give results equivalent to (6.3), due to the non-
local character of the Hamiltonian (6.1). In general, one could choose other non-extensive
operators, such as the number operator at a particular site ni := c†
ici. Both ni and hij
have been shown numerically to satisfy ETH [36].
We studied samples with L = 8, 9 and 10 sites. The numerical results for SYK4 with
L = 10 are shown in Figures 1, 2 and 3. For details on the scaling properties of the b-
sequence, K-complexity and K-entropy with system size, see Figures 4, 5, 6 and 7, as well
as the summarizing Table 1.
The global picture emerging from these results can be summarized in the following
bullet points:
– 10 –


---

Figure 3. K-entropy averaged over 5 random realizations with L = 10 sites at half ﬁlling. Left:
Full time range computed, with logarithmic scale along horizontal axis. A linear ﬁt in the post-
scrambling regime, where K-entropy is expected to grow logarithmically, is depicted in red. K-
entropy grows linearly up to scrambling time, and then transitions to a logarithmic growth phase
that continues until saturation around SK ∼L ∼S at exponentially late times (this is the time
scale at which the wave-packet ϕn(t) becomes fully dispersed). Right: K-entropy at early times
with linear scale along the horizontal axis. The exact location of the time scales may depend on a
dimensionful prefactor (see caption of Figure 2).
• The Descent and its associated Lanczos sequence. The length of the Lanczos
sequence saturates its upper bound.
It features a period of initial growth up to
n ∼S, followed by a regime of slow decrease to zero with roughly constant negative
non-perturbative slope of order ∼−e−2S, the Descent.
• K-complexity features a transition from exponential growth at very early times
to linear increase.
At exponentially late times it saturates at half of the Krylov
dimension, since by then the operator is uniformly distributed over the Krylov basis.
• K-entropy grows linearly up to scrambling time, and then transitions to a logarith-
mic growth phase that continues until saturation around SK ∼S at exponentially
late times.
The relationship between the Lanczos sequence bn and quantities like CK(t) and SK(t)
is highly non-linear, which is why disorder averages need to be performed with caution.
The Lanczos sequence is not really a physical observable and averaging is just used as a tool
to gain knowledge about the envelope of its proﬁle. However, in order to obtain averaged
K-complexity or K-entropy as a function of time, one should compute these quantities
separately for each random realization of the Hamiltonian and average over the outcomes
in a ﬁnal step. Averaging over the Lanczos sequence before computing CK and SK results
in a smoothing of the b-sequence that stops the wave packet from randomizing eﬃciently
before reaching the edge of the Krylov chain, being therefore reﬂected due to the boundary
conditions. These rebounds would be reﬂected by large, un-physical oscillations in the
proﬁles of CK and SK, an eﬀect that has been conﬁrmed by numerical simulations.
– 11 –


---

Figure 4. Lanczos sequences for L = 8, N = 4 and L = 9, N = 5 and comparison of results for
L = 8, 9, 10. Top row: Results for L = 8 in linear (left panel) and logarithmic (right panel) scale
along the horizontal axis. The plots depict both the sequence of a single random realization and the
average over 311 realizations. A linear ﬁt is included in the decaying tail, whose slope approaches
numerically the na¨ıve estimate ∼−1
K ≈−0.000206. Middle row: Results for L = 9 in linear
(left panel) and logarithmic (right panel) scale along the horizontal axis. The plots depict both the
sequence of a single random realization and the average over 50 realizations. A linear ﬁt is included
in the decaying tail, whose slope is of the order of the naive estimate ∼−1
K ≈−6.3·10−5. Bottom
row: Comparison of the Lanczos sequences for L = 8, 9, 10 in linear (left panel) and logarithmic
(right panel) scale along the horizontal axis.
log(L)
L
D
K/2
bn slope
CK sat.
SK sat.
2.07944
8
70
2415.5
−0.00026
2215
7.7
2.19722
9
126
7875.5
−8.6 × 10−5
7254
8.9
2.30258
10
252
31626.5
−2.21 × 10−5
29,618
10.3
Table 1. Summary Table of the numerical phenomenology observed. Values averaged over several
random realizations. In terms of S, log(L) ∼log(S), L ∼S, D ∼eS and K ∼e2S.
7
Discussion
On the analytical side, we have found an algorithmic expression for the dimension of Krylov
space K.
This quantity is very sensitive to the degeneracy structure of the spectrum
– 12 –


---

Figure 5. Results for K-complexity for L = 8, N = 4 and L = 9, N = 5 and comparison of results
for L = 8, 9, 10. Top row: Results for L = 8; for exponentially long times (left panel) and for early
times (right panel). Note the change in behaviour from very early times (inset) and later times. The
value at saturation is near ∼K
2 = 2415.5. Middle row: Results for L = 9; for exponentially long
times (left panel) and for early times (right panel). The value at saturation is near ∼K
2 = 7875.5.
Bottom row: Comparison of results for L = 8, 9, 10 for exponentially long times (left panel) and
for early times (right panel).
and is always strictly smaller than the dimension of operator space D2, since it satisﬁes
K ≤D2 −D + 1.
Typical operators in chaotic systems are expected to saturate this
bound, due to the absence of degeneracies, whereas in integrable systems K will typically
be signiﬁcantly smaller than its upper bound (at least eﬀectively up to late times), as
veriﬁed analytically for SYK2. Furthermore, numerical observations in SYK4 and RMT
suggest that the bn-proﬁle featuring a slow decrease to zero given by a non-perturbative
slope of order e−2S – the Descent – may be a generic feature of quantum chaotic systems.
It is worth noting that, since K-complexity is nothing but an average position in Krylov
space, the above bound on K translates directly into an upper bound for CK(t). We note
that although K-complexity features the proﬁle expected from circuit complexity, there
are notable diﬀerences between them: Krylov complexity does not depend on an arbitrary
tolerance parameter, and it does depend on both the Hamiltonian of the system and the
operator whose K-complexity is measured over time. This may have impact in situations
that involve more than one operator insertion. We hope to address this and other related
– 13 –


---

Figure 6. Results for K-entropy for L = 8, N = 4 and L = 9, N = 5. Top row: Results for L = 8;
for exponentially long time scales in linear (left panel) and logarithmic (middle panel) scale along
the horizontal axis, and for early times (right panel). The saturation value is near L = 8. Bottom
Row: Results for L = 9; for exponentially long time scales in linear (left panel) and logarithmic
(middle panel) scale along the horizontal axis, and for early times (right panel). The saturation
value is near L = 9.
Figure 7. Comparison of results for K-entropy for L = 8, 9, 10; for long time scales (left panel),
and for early times (right panel).
issues in the future.
We end by returning to an issue we emphasized at the outset, namely that K-complexity
is naturally bounded. This is a direct consequence of the ﬁnite dimensionality of the Hilbert
space, and thus has the same origin as the plateau in the spectral form factor and correlation
functions. We conjecture that other late-time universal characteristics of quantum chaos,
namely the dip-ramp-plateau structure [7], also leave their imprint on K-complexity. The
putative bulk realization of K-complexity should therefore be sensitive to bulk Euclidean
wormholes and baby universes [37], in ensemble-averaged systems, such as SYK, as well as
in individual quantum chaotic systems, as has been emphasized in [17].
Note added: in the ﬁnal stages of preparation of this paper, the work [38] appeared on
the arxiv studying, among other things, some aspects of K-complexity in SYK. Up to the
timescales they consider, our results are consistent with theirs.
– 14 –


---

Figure 8. Lanczos sequence for RMT drawn from the GUE with potential (A.1). The Hilbert
space dimension was chosen to match that of cSYK with L = 9 and N = 5. The right panel
features the same data, with logarithmic scale along horizontal axis, allowing more resolution on
the initial part of the sequence.
Acknowledgments
We would like to thank Jos´e Barb´on as well as D. Aharonov, M. Ben-Or, N. Katz, P. Nayak,
H. Neuberger, J. Rougemont and M. Vielma for enlightening discussion. ER would like to
thank NHETC at Rutgers Physics Department and CCPP at NYU for hospitality. The
numerical computations in this paper were performed on the Baobab HPC cluster at the
University of Geneva and on the Landau cluster at the Hebrew University. This work has
been supported by the SNF through Project Grants 200020 182513, the NCCR 51NF40-
141869 The Mathematics of Physics (SwissMAP). The work of ER and RS is partially
supported by the Israeli Science Foundation Center of Excellence. We thank the organisers
of the conference “Frontiers in Holography” (May 2020, Moscow), where the results of this
work were presented.
A
Lanczos sequence in RMT
Some preliminary numerical checks have indicated that RMT reproduces qualitatively the
features observed in complex SYK with q = 4, that is: saturation of the upper bound
for Krylov space, K = D2 −D + 1, and slow decrease of the b-sequence to zero after
initial growth, with a non-perturbative slope of order ∼−1
K ∼−e−2S, S being the entropy
(system size). Figure 8 depicts the Lanczos sequence of a system whose Hamiltonian H is
drawn from a GUE with potential:
V (H) = D
2J2 Tr
 H2
(A.1)
where D is the Hilbert space dimension and J is the coupling strength that sets energy
scales. A more detailed numerical and analytical study of the Lanczos sequence in RMT
constitutes work in progress, but these preliminary checks make it natural to conjecture
that the discussed features are universal in chaotic systems.
– 15 –


---

B
Krylov space for SYK2
Given the SYK2 model described in 3.1, we can proceed to apply the Lanczos algorithm
analytically to the operator O = χA.
We will use the Frobenius scalar product deﬁned in the main text, recalling that the
dimension of the Hilbert space of states in this case is D = 2M. It is not diﬃcult to prove
that:
(χi|χj) = 1
2δij .
(B.1)
• O0: Making use of (B.1) one ﬁnds that our starting operator is not normalized, since
(O|O) = 1
2, so:
O0 =
O
p
(O|O)
=
√
2O =
√
2 χA .
(B.2)
• O1: One ﬁrst needs to compute A1:
A1 = [H, O0] = i
√
2
2
L=2M
X
i,j=1
mij [χiχj, χA]
(B.3)
We make use of the commutator of the fermionic bilinear with the single Majorana:
[χiχj, χA] = δAjχi −δAiχj
(B.4)
so that ﬁnally
A1 = [H, O0] = i
√
2
L=2M
X
i=1
i̸=A
miAχi .
(B.5)
The ﬁrst Lanczos coeﬃcient is:
b1 =
p
(A1|A1) =
v
u
u
u
u
u
t
2
L=2M
X
i,j=1
i̸=A
j̸=A
miAmjA (χi|χj)
(B.6)
and recalling (B.1) one ﬁnds:
b1 =
v
u
u
u
t
L=2M
X
i=1
i̸=A
m2
iA .
(B.7)
Thus, the next Krylov element is:
O1 = 1
b1
A1 =
i
√
2
v
u
u
u
t
L=2M
X
i=1
i̸=A
m2
iA
L=2M
X
i=1
i̸=A
miA χi .
(B.8)
– 16 –


---

The form of (B.7) allows the computation of the ensemble average of the ﬁrst Lanczos
coeﬃcient, since the calculation will turn out to be simple if one makes use of spherical
coordinates in sample space:
E (b1) =
Z
dL−1x b(x)P(x)
(B.9)
where we deﬁned b(x) ≡
√
x2, and note that there are L−1 random variables because
(B.7) only involves L−1 independent coupling strengths. The probability distribution
is a product of Gaussians:
P(x) =
L−1
Y
i=1
ρ(xi),
ρ(xi) =
1
σ
√
2πe−
x2
i
2σ2
(B.10)
where, in agreement with E(m2
ij) = m2/L, the standard deviation is given by σ =
m
√
L.
As promised, the use of spherical coordinates greatly simpliﬁes the computation and
the result is:
E (b1) =
Γ
  L
2

Γ
  L−1
2

r
2
Lm L→+∞
−→
m .
(B.11)
• More elements: It can be an interesting task to compute in closed form the rest
of the Lanczos sequence, but we can already anticipate what its length will be: As
shown in (B.4), the commutator of a bilinear with a single-site operator will still
yield a linear combination of Majoranas on a single site, so A2 = [H, O1] −b1O0 will
still be a one-site operator, and so will the rest of the Krylov elements. Hence the
maximum possible number of linearly independent Krylov elements will be given by
the number of sites of the system, that is to say, in this integrable system the Krylov
dimension K is bounded by:
K ≤L ∼log D ≪D2 −D + 1
(B.12)
i.e. the Krylov space scales at most linearly with entropy (system size), instead of
with the operator space dimension (exponential in entropy).
C
Numerical algorithms
It is known that the original Lanczos algorithm, as presented in the main text, features
an important numerical instability [34, 35, 39]: the construction of each Krylov element
makes use of the two previous ones, so errors due to ﬁnite-precision arithmetic accumulate
dramatically and orthogonality of the Krylov basis is soon lost in numerical computations.
Residual overlaps between Krylov elements grow exponentially (or even faster) with the
iteration number n, which makes the Lanczos coeﬃcients unreliable after a few iterations.
In particular, the original Lanczos algorithm doesn’t feature the termination of the sequence
by hitting a zero at n = K when run with ﬁnite precision, and instead it generally outputs a
Lanczos sequence that oscillates wildly around some constant value, whose disorder average
yields a completely ﬂat sequence (after initial growth) in complex SYK; this is purely a
– 17 –


---

product of numerical precision errors and needs to be corrected in order to shed light on
the structure of the b-sequence along the full length of the Krylov chain. Some numerical
algorithms need to be implemented in order to cure this instability, allowing observation of
the slow decay to zero of the Lanczos coeﬃcients after the initial growth in complex SYK.
Such algorithms are described below.
C.1
Full Orthogonalization (FO)
This algorithm [35] performs a brute-force re-orthogonalization of the newly constructed
Krylov element with respect to the previous ones at every iteration of the Lanczos al-
gorithm, ensuring orthonormality of the Krylov basis up to machine precision εM. The
algorithm is not very eﬃcient time-wise, and is also costly in terms of memory, since the
whole Krylov basis needs to be stored and is used in every iteration, it is therefore used
mainly when one wants to compute only part of the Lanczos-sequence (see for example the
recent work [40]). However, for small samples, FO can be used safely and one can check
that the results yielded agree with the theoretical predictions described previously in this
article (length of the Lanczos sequence, termination by hitting a zero, eigenvalues of the
tri-diagonal matrix matching those corresponding to the eigenspace representatives that
span the Krylov space).
The FO algorithm amounts to performing explicit Gram-Schmidt at every iteration in
the Lanczos algorithm to ensure orthogonality (up to machine precision). For numerical
purposes, it is usually optimal to perform Gram-Schmidt twice every time:
1. |O0) =
1
√
(O|O) |O).
2. For n ≥1: Compute |An) = L |On−1).
3. Re-orthogonalize |An) explicitly with respect to all previous Krylov elements:
|An) 7−→|An) −Pn−1
m=0 |Om) (Om|An).
4. Repeat step 3.
5. Set bn =
p
(An|An).
6. If bn = 0 stop; otherwise set |On) =
1
bn |An) and go to step 2.
C.2
Partial Re-Orthogonalization (PRO)
This algorithm [34] allows the residual overlaps between Krylov elements to grow up to a
certain threshold, and re-orthogonalization is only performed when the threshold is crossed.
For a machine precision εM, the threshold is typically taken to be √εM.
In our notation, the recursion relation for the Krylov basis is, including ﬁnite-precision
errors:
bn |On) = L |On−1) −bn−1 |On−2) + |ξn−1)
(C.1)
where |ξn−1) accounts for some spurious vector generated by accumulated numerical errors.
All the objects denoted above represent the quantities numerically computed, rather than
– 18 –


---

the actual (analytically exact) Lanczos coeﬃcients and Krylov elements. Acting with (Ok|
from the left:
bn (Ok |On) = (Ok| L |On−1) −bn−1 (Ok |On−2) + (Ok |ξn−1)
(C.2)
where we recall that (Ok| L |On−1) = Tk,n−1, T being the tri-diagonal symmetric matrix
built out of the Lanczos sequence, see (4.1). We now deﬁne the matrix W, with items
Wkn = (Ok |On), that is:
(Wkn) =






W00 = (O0 |O0) W01 = (O0 |O1) W02 = (O0 |O2) . . .
W11 = (O1 |O1) W12 = (O1 |O2) . . .
W22 = (O2 |O2) . . .
...
...
...
...






(C.3)
Even though we don’t write all the entries in the matrix, it’s hermitian by deﬁnition
of the scalar product (·|·), so W = W † ⇐⇒Wkn = W ∗
nk. In the PRO algorithm, however,
we construct iteratively the entries written explicitly in (C.3): For a given n we’ll want to
estimate Wkn, for k ≤n. We do so by noticing that (C.2) is nothing but:
bnWkn = Tk,n−1 −bn−1Wk,n−2 + (Ok |ξn−1) .
(C.4)
Renaming indices k ↔n −1 (i.e. k 7→n −1 and n 7→k + 1):
bk+1Wn−1,k+1 = Tn−1,k −bkWn−1,k−1 + (On−1 |ξk) .
(C.5)
Computing (C.4) −(C.5), recalling that T is symmetric and solving for Wkn:
Wkn = 1
bn

bk+1W ∗
k+1,n−1 + bkW ∗
k−1,n−1 −bn−1Wk,n−2
+ (Ok |ξn−1) −(On−1 |ξk)] .
(C.6)
We want to use (C.6) to determine, for a ﬁxed n, all Wkn with k ≤n given that we
know all {Wij, i = 0, ..., j, ∀j = 0, ..., n −1} (according to what we depicted in (C.3): we
compute iteratively each upper-diagonal column making use of the previous ones).
We note that Wnn is not determined by (C.6) in terms of previous upper-diagonal
columns, but we can set it to Wnn = 1 because in the n-th Lanczos step, |On) is explicitly
normalized to unity. Likewise, Wn−1,n is not determined from (C.6) in terms of previous
columns, and the Lanczos recursion (C.1) doesn’t explicitly orthogonalize |On) against
|On−1), so we will need to orthogonalize them explicitly, and then set Wn−1,n = O (εM)
(i.e. zero up to machine precision).
Also, an estimate for (Ok |ξn−1) −(On−1 |ξk) is needed. One can take something of
order of the machine precision times the norm of the Liouvillian:
 (Ok |ξn−1) −(On−1 |ξk)
 ∼2εM∥L∥
(C.7)
where
L
 should be the norm of the Liouvillian induced by the scalar product (·|·) in
the Hilbert space of operators. For practical applications, this contribution can just be
ignored, since in any case each iteration of the algorithm will already generate spurious
errors of order εM.
All in all, the LanPRO algorithm reads:
– 19 –


---

• Compute |O0) =
1
√
(O |O) |O).
– Set W00 = 1.
• Compute |A1) = L |O0).
– Orthogonalize it explicitly with respect to |O0).
– Compute b1 =
p
(A1|A1). If b1 < √εM stop. Otherwise compute |O1) =
1
b1 |A1).
– Set W01 = εM and W11 = 1.
• Loop for n ≥2, and for every n do:
– Compute |An) = L |On−1) −bn−1 |On−2).
– Compute the a-priori Lanczos coeﬃcient:
bn =
p
(An|An).
– If bn < √εM break, otherwise continue...
– Orthogonalize explicitly |An) with respect to |On−1).
– Set Wn,n = 1 and Wn−1,n = εM.
– Loop for all k = 0, ..., n −2, determine Wkn doing:
f
W = bk+1W ∗
k+1,n−1 + bkW ∗
k−1,n−1 −bn−1Wk,n−2
Wkn = 1
bn
"
f
W +
f
W
f
W
 · 2εM∥L∥
#
(C.8)
– If there is some k ≤n −2 such that Wkn > √εM, do:
∗Re-orthogonalize explicitly |An) and |An−1) with respect to all previous
Krylov elements.
∗From the new |An−1), re-compute bn−1. Break if bn−1 < √εM, otherwise
re-compute |On−1).
∗From the new |An), re-compute bn. Break if bn < √εM, otherwise com-
pute |On) =
1
bn |An).
∗Set Wa,n−1 = δa,n−1+(1 −δa,n−1) εM, for all a = 0, ..., n −1.
∗Set Wa,n = δa,n+(1 −δa,n) εM, for all a = 0, ..., n.
– Otherwise compute |On) =
1
bn |An).
(End of algorithm).
Some comments are in order:
• In every iteration n ≥2, only the two previous upper-diagonal columns {Wk,n−1, k = 0, ..., n −1}
and {Wk,n−2, k = 0, ..., n −2} of the matrix W are required. This is why, whenever
re-orthogonalization is required, one only carries it out for |An−1) and |An).
– 20 –


---

• Whenever re-orthogonalization is needed, it is optimal to perform it twice, in the
same way Gram-Schmidt is applied twice at every step of the FO algorithm.
In the case of complex SYK4, for the system sizes studied in this article and a typical
ﬂoating point precision of εM ∼10−15, PRO reduces the number of re-orthogonalizations
required by approximately a factor of 10, as compared to FO.
References
[1] Juan Martin Maldacena. Eternal black holes in anti-de Sitter. JHEP, 04:021, 2003.
[2] J.L.F. Barb´on and E. Rabinovici. Very long time scales and black hole thermal equilibrium.
JHEP, 11:047, 2003.
[3] Lisa Dyson, Matthew Kleban, and Leonard Susskind. Disturbing implications of a
cosmological constant. JHEP, 10:011, 2002.
[4] Leonard Susskind. Computational Complexity and Black Hole Horizons. Fortsch. Phys.,
64:24–43, 2016. [Addendum: Fortsch.Phys. 64, 44–48 (2016)].
[5] Douglas Stanford and Leonard Susskind. Complexity and Shock Wave Geometries. Phys.
Rev. D, 90(12):126007, 2014.
[6] Jose L.F. Barb´on and Eliezer Rabinovici. Geometry And Quantum Noise. Fortsch. Phys.,
62:626–646, 2014.
[7] Jordan S. Cotler, Guy Gur-Ari, Masanori Hanada, Joseph Polchinski, Phil Saad, Stephen H.
Shenker, Douglas Stanford, Alexandre Streicher, and Masaki Tezuka. Black Holes and
Random Matrices. JHEP, 05:118, 2017. [Erratum: JHEP 09, 002 (2018)].
[8] Adam R. Brown and Leonard Susskind. Second law of quantum complexity. Phys. Rev. D,
97(8):086015, 2018.
[9] Daniel E. Parker, Xiangyu Cao, Alexander Avdoshkin, Thomas Scaﬃdi, and Ehud Altman.
A Universal Operator Growth Hypothesis. Phys. Rev. X, 9(4):041017, 2019.
[10] J.L.F. Barb´on, E. Rabinovici, R. Shir, and R. Sinha. On The Evolution Of Operator
Complexity Beyond Scrambling. JHEP, 10:264, 2019.
[11] L. Garc´ıa-´Alvarez, I.L. Egusquiza, L. Lamata, A. del Campo, J. Sonner, and E. Solano.
Digital Quantum Simulation of Minimal AdS/CFT. Phys. Rev. Lett., 119(4):040501, 2017.
[12] Ryan Babbush, Dominic W Berry, and Hartmut Neven. Quantum simulation of the
sachdev-ye-kitaev model by asymmetric qubitization. Physical Review A, 99(4):040301, 2019.
[13] A Yu Kitaev. Quantum computations: algorithms and error correction. Russian
Mathematical Surveys, 52(6):1191–1249, dec 1997.
[14] Michael A. Nielsen and Isaac L. Chuang. Quantum Computation and Quantum Information:
10th Anniversary Edition. Cambridge University Press, 2010.
[15] Christopher M. Dawson and Michael A. Nielsen. The solovay-kitaev algorithm, 2005.
[16] Daniel A. Roberts, Douglas Stanford, and Alexandre Streicher. Operator growth in the SYK
model. JHEP, 06:122, 2018.
[17] Alexander Altland and Julian Sonner. Late time physics of holographic quantum chaos. 8
2020.
– 21 –


---

[18] V.S. Viswanath and G. M¨uller. The Recursion Method. Springer-Verlag Berlin Heidelberg,
1994.
[19] C. Lanczos. An iteration method for the solution of the eigenvalue problem of linear
diﬀerential and integral operators. Journal of research of the National Bureau of Standards,
45:255–282, 1950.
[20] Subir Sachdev and Jinwu Ye. Gapless spin ﬂuid ground state in a random, quantum
Heisenberg magnet. Phys. Rev. Lett., 70:3339, 1993.
[21] Alexei Kitaev. A simple model of quantum holography. KITP talks, 2015.
[22] Subir Sachdev. Bekenstein-Hawking Entropy and Strange Metals. Phys. Rev. X, 5(4):041025,
2015.
[23] Juan Maldacena and Douglas Stanford. Remarks on the Sachdev-Ye-Kitaev model. Phys.
Rev. D, 94(10):106002, 2016.
[24] Antonio M. Garc´ıa-Garc´ıa and Jacobus J. M. Verbaarschot. Spectral and thermodynamic
properties of the Sachdev-Ye-Kitaev model. Phys. Rev. D, 94(12):126010, 2016.
[25] Antonio M. Garc´ıa-Garc´ıa, Bruno Loureiro, Aurelio Romero-Berm´udez, and Masaki Tezuka.
Chaotic-Integrable Transition in the Sachdev-Ye-Kitaev Model. Phys. Rev. Lett.,
120(24):241603, 2018.
[26] Antonio M. Garc´ıa-Garc´ıa, Yiyang Jia, Dario Rosa, and Jacobus J.M. Verbaarschot. Sparse
Sachdev-Ye-Kitaev model, quantum chaos and gravity duals. 7 2020.
[27] Masudul Haque and P. A. McClarty. Eigenstate thermalization scaling in majorana clusters:
From chaotic to integrable sachdev-ye-kitaev models. Physical Review B, 100(11), Sep 2019.
[28] A. Krylov. De la r´esolution num´erique de l’´equation servant `a d´eterminer dans des questions
de m´ecanique appliqu´ee les fr´equences de petites oscillations des syst`emes mat´eriels. Bulletin
de l’Acad´emie des Sciences de l’URSS. Classe des sciences math´ematiques et naturelles,
4:491–539, 1931.
[29] Asher Peres. Ergodicity and mixing in quantum theory. i. Phys. Rev. A, 30:504–508, Jul
1984.
[30] J. M. Deutsch. Quantum statistical mechanics in a closed system. Phys. Rev. A,
43:2046–2049, Feb 1991.
[31] Mark Srednicki. The approach to thermal equilibrium in quantized chaotic systems. Journal
of Physics A: Mathematical and General, 32(7):1163–1175, Jan 1999.
[32] Luca D’Alessio, Yariv Kafri, Anatoli Polkovnikov, and Marcos Rigol. From quantum chaos
and eigenstate thermalization to statistical mechanics and thermodynamics. Adv. Phys.,
65(3):239–362, 2016.
[33] Matteo Carrega, Joonho Kim, and Dario Rosa. Unveiling operator growth in SYK quench
dynamics. 7 2020.
[34] Horst D. Simon. The lanczos algorithm with partial reorthogonalization. Mathematics of
Computation, 42(165):115–142, 1984.
[35] Beresford N. Parlett. The Symmetric Eigenvalue Problem. Society for Industrial and Applied
Mathematics, 1998.
[36] Julian Sonner and Manuel Vielma. Eigenstate thermalization in the Sachdev-Ye-Kitaev
model. JHEP, 11:149, 2017.
– 22 –


---

[37] Phil Saad, Stephen H. Shenker, and Douglas Stanford. JT gravity as a matrix integral. 3
2019.
[38] Shao-Kai Jian, Brian Swingle, and Zhuo-Yu Xian. Complexity growth of operators in the
SYK model and in JT gravity. 8 2020.
[39] B. N. Parlett and D. S. Scott. The lanczos algorithm with selective orthogonalization.
Mathematics of Computation, 33(145):217–238, 1979.
[40] Daniel J. Yates, Alexander G. Abanov, and Aditi Mitra. Dynamics of almost strong edge
modes in spin chains away from integrability. Physical Review B, 102(19), Nov 2020.
– 23 –


---
*Full text extracted from PDF for MemoVoice V3 algorithm training.*

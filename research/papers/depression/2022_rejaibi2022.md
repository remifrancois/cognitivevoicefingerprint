# Rejaibi2022 et al. (2022) — Full Text Extraction

**Source file:** 2022_rejaibi2022.pdf
**Pages:** 48
**Extracted by:** MemoVoice research pipeline (PyMuPDF)

---

## Full Paper Content

The application of machine
learning for infant cries
classiﬁcation and
pathological cries
detection: A systematic
review
Sudhathai Sirithepmontree1,2
, Nattasit Katchamat1,3
and Sasitara Nuampa2
Abstract
Objective: This study aims to systematically review and synthesize the studies on the
application of machine learning for classifying infant cry types, identifying pathological
cries, and evaluating the accuracy of infant cry recognition.
Methods: This review followed the PRISMA guidelines and was registered in
PROSPERO (CRD42024600969). The literature search was conducted on four data
sources: PubMed, CINAHL, Embase, and IEEE Xplore. The included studies focused
on machine learning-based classiﬁcation of infants’ needs cries or pathological cries.
These were published in English between January 1, 2014 and October 31, 2024.
Study quality was assessed using the QUADAS-2 tool.
Results: Of 919 studies were identiﬁed, 17 were included in the ﬁnal synthesis. Machine
learning can classify infant cries into two main types: infant needs’ cries and pathological
1School of Nursing, The University of Texas at Austin, Austin, TX, USA
2Faculty of Nursing, Mahidol University, Bangkok, Thailand
3Ramathibodi School of Nursing, Faculty of Medicine Ramathibodi Hospital, Mahidol University, Bangkok,
Thailand
Corresponding author:
Sudhathai Sirithepmontree, School of Nursing, The University of Texas at Austin, 1710 Red River Street,
Austin, TX 78712, USA; Faculty of Nursing, Mahidol University, 2 Wang Lang Road, Siriraj, Bangkoknoi,
Bangkok 10700 Thailand.
Email: sudhathai.s@utexas.edu
Creative Commons Non Commercial CC BY-NC: This article is distributed under the terms
of the Creative Commons Attribution-NonCommercial 4.0 License (https://
creativecommons.org/licenses/by-nc/4.0/) which permits non-commercial use, reproduction and distribution of
the work without further permission provided the original work is attributed as speciﬁed on the SAGE and
Open Access page (https://us.sagepub.com/en-us/nam/open-access-at-sage).
The digital transformation of healthcare: Exploring the
role of AI in improving patient-centered care—
The digital transformation of healthcare: Explorin-Review SCIENCE PROGRESS
Science Progress
2026, Vol. 109(1) 1–48
© The Author(s) 2026
Article reuse guidelines:
sagepub.com/journals-permissions
DOI: 10.1177/00368504251410776
journals.sagepub.com/home/sci


---

cries, with some studies addressing both. Needs-related cries comprised nine subtypes,
while pathological cries included six subtypes. Classiﬁcation accuracy varied by machine
learning classiﬁer and the features used, ranging from 44.5% to 99.82%. The highest
accuracy for infant needs’ cries was hunger and pain cries at 99.82% using a Gaussian
mixture model (GMM) classiﬁer with constant-Q cepstral coefﬁcients features. For
pathological cries, the highest accuracy was for detecting deafness (99.42% to
99.82%), using a genetic selection of Fuzzy Model and a GMM classiﬁer.
Conclusions: Machine learning shows strong potential for accurately classifying infant
cries and detecting pathologies. Future research should prioritize developing diverse cry
datasets to improve model generalizability, evaluating performance in real-world settings,
and integrating cry analysis with physiological signals to enhance diagnostic accuracy.
Keywords
Machine learning, infant cry, pathological cry, infant health, classiﬁcation, systematic
review
Introduction
Infant cries are one of the infant cues, which are signals that infants communicate and
interact with their caregivers. These signals can convey the needs of infants and reﬂect
pathological disorders.1 Crying can be considered as the natural behavior of an infant
and is identiﬁed based on the infant’s needs, such as hunger, pain, discomfort, diaper,
and sleepiness.2,3 Moreover, an infant’s cries can indicate health issues or illnesses,
such as infections, respiratory distress syndrome (RDS), or neurological conditions.1,4,5
Since infants are unable to communicate verbally, it is essential for caregivers to interpret
the meaning behind their cries. This understanding is the key to providing appropriate
responses to infants. However, infant cries encompass a wide range of meanings, which
can make it challenging to interpret them accurately, especially for ﬁrst-time mothers who
lack experience in caring for babies and are more likely to misinterpret than experienced
mothers, leading to inappropriate responses.6
The principles of the maternal sensitivity concept can explain the responsiveness to the
infant’s needs.7 This framework includes the dynamic process of perceiving, interpreting,
and responding to the infant’s signals based on previous caregiving experience and the
quality of caregiver–infant interaction. A responsive mother can accurately perceive
the infant’s signals, interpret, and respond appropriately to enhance infant development
and attachment. On the other hand, difﬁculties in interpreting or responding to infant cries
may increase stress and risk of psychological or physical health problems for caregivers.
Petzoldt et al.8 found that ﬁrst-time mothers of excessive crying infants were more likely
to develop anxiety disorders due to a lack of infant care experiences. Similarly,
Oberlander and Rotem-Kohavi9 indicated that an inability to respond to infant cries
can contribute to postpartum depression. In terms of physical health effects, Brand
et al.10 indicated that caregivers who struggle with infant crying may experience sleep
disturbances, depressive symptoms, and family strain.
2
Science Progress 109(1)


---

The analysis of infant cries has demonstrated that pathological conditions can be eval-
uated through acoustic cry analysis. Valdes et al.1 identiﬁed speciﬁc acoustic features that
can distinguish normal cries from pathological cries based on the characteristics of the
infant’s voice. For instance, healthy cries are typically loud and exhibit an ascending–des-
cending melody pattern with a frequency range of 400 to 650 Hz. In contrast, abnormal
cries tend to have a shorter duration, monotonous melody, and a higher frequency than
650 Hz. Infant cries can serve as a valuable tool for identifying pathological conditions
in medical diagnosis. For example, in diseases affecting the central nervous system, cries
exhibit extremely high frequencies of 3000–4000 Hz. Conversely, in hypothyroidism, the
cries have a lower fundamental frequency than normal cries, but the spectrogram is simi-
lar to healthy cries. While the differences between normal and pathological cries can be
identiﬁed based on their acoustic characteristics, distinguishing them with accuracy
remains challenging, particularly in medical diagnostics that require precise evaluation.
Traditionally, several studies on infant cries have assumed the existence of distinct cry
types, such as hunger, pain, or discomfort cries, which can be acoustically differentiated
and classiﬁed.2,3,11,12 However, this typological perspective has been challenged by the
graded cry hypothesis, which proposes that infant cries vary along a continuum of arousal
or distress rather than representing discrete categories.13,14 According to this view, acous-
tic differences primarily reﬂect the intensity of distress rather than speciﬁc needs. This
debate is critical for cry classiﬁcation studies: if cries are graded rather than categorical,
then labeling them as ﬁxed types may impose artiﬁcial boundaries. In medical or clinical
practice, relying solely on distress levels can make it difﬁcult to diagnose or detect patho-
logical conditions, since pathological cries may share similar acoustic markers with
highly distressed but otherwise healthy infants.15 Therefore, before evaluating how
effectively algorithms can classify infant cries, it is essential to consider how the cries
are labeled. The labeling process is crucial and should account for how each cry was iden-
tiﬁed. In clinical and research settings, the practical approach to cry labeling often relies
on contextual cues, such as the action that successfully stops the cry or the stimulus pre-
ceding it. For example, Liang et al.16 labeled cries based on the action that stopped the
crying (e.g. a hunger cry was identiﬁed when the infant stopped crying after being fed)
or based on the event that caused the crying (e.g. a pain cry was labeled during invasive
procedures). Similarly, Parga et al.15 ensured labeling reliability by having two medical
staff independently identify each audio recording, with pain cries captured during painful
stimuli. However, identifying distinct cry types remains challenging, particularly under
the graded cry hypothesis, which suggests that cries vary along a continuum of arousal
or distress rather than existing as discrete categories.14 This underscores the need to care-
fully consider how labels are deﬁned and validated before they are used to train machine
learning (ML) models. Additionally, ML approaches learn from acoustic features that
vary along a continuum and transform these graded patterns into categorical outputs,
bridging the gap between continuous vocal variation and relevant classiﬁcations.17
In the current era of advanced technology, ML has been utilized to help recognize and
differentiate infant cries, providing a helpful solution to these problems. ML is the subset
of artiﬁcial intelligence, which uses algorithms based on the knowledge gained from past
data to forecast and make decisions for a speciﬁc domain.18 ML models can predict,
Sirithepmontree et al.
3


---

categorize, and cluster through supervised learning that algorithms learn patterns from
numerical values based on historical data.19 For example, in adult patients, Jian et al.20
studied ML classiﬁcation algorithms to predict and classify eight diabetes complications,
reaching 97.8% accuracy. In the ﬁeld of pediatrics, Tesfaye et al.21 developed ML to pre-
dict childhood anemia using sociodemographic, economic, and maternal and child vari-
ables. The accuracy of their predictive performance ranged from 60% to 66%.
In maternal and infant care, ML has been used to classify and recognize infant cries,
enhancing caregivers’ understanding of an infant’s signals. Although the human ability to
understand an infant’s cry should not be overlooked, a well-constructed computer system
can provide more accurate solutions to audio classiﬁcation. Mukhopadhyay et al.22 com-
pared the accuracy performance in differentiating infant cry types between human and
ML, with humans achieving 33.09% accuracy. In contrast, ML achieved 80.56% accur-
acy on the same dataset. Moreover, ML is also utilized in healthcare systems to differen-
tiate between the cries of healthy and sick infants. For example, Zayed et al.23 applied ML
to classify healthy, sepsis, and respiratory distress cries. Similarly, Rosales-Pérez et al.24
used ML to distinguish between pathological cries (e.g. asphyxia and deafness) and spe-
ciﬁc need cries (e.g. hunger and pain).
From previous literature reviews on maternal and infant care, several studies have
explored the application of ML in predicting neonatal mortality,25 neonatal outcomes
in neonatal intensive care units,26 preterm birth,27 and pregnancy complications.28
However, there is a lack of systematic reviews speciﬁcally focusing on the application
of ML to classify infant cries based on pattern recognition. Therefore, the purpose of
this study is to systematically review the studies on the application of ML in classify-
ing infant cry types and identifying pathological cries, as well as evaluating the accur-
acy of classiﬁcation. This review focuses on research studies published between
January 2014 and October 2024 to provide the most recent coverage of evidence.
The research questions of this study are: (1) How has ML been used to classify infant
cry types and pathological cries? (2) How accurately can ML classiﬁer recognize pat-
terns in infant cries?
Methods
Protocol and registration
This systematic review was conducted following the methodological guidelines of sys-
tematic reviews and reported according to the Preferred Reporting Items for
Systematic Reviews and Meta-Analyses (PRISMA 2020) framework.29 A narrative syn-
thesis approach was employed to describe the ﬁndings. The study protocol has been regis-
tered with the PROSPERO database (registration number: CRD42024600969).
Eligibility criteria
Inclusion criteria: Studies were included if they focused on classifying infant cries based
on needs or detecting pathological cries using ML algorithms. They must also employ
4
Science Progress 109(1)


---

observational designs, such as cohort studies, case-control studies, or cross-sectional
studies, and infant’s age no more than 2 years. The studies published in English between
January 1st, 2014 and October 31st, 2024 were included.
Exclusion criteria: Studies were excluded if they did not specify the type of ML clas-
siﬁer, features, or did not report outcomes related to the crying type and performance data
of the classiﬁcations (accuracy, sensitivity, or speciﬁcity rate). To ensure the rigorous and
reliability of the review’s ﬁndings, gray literature, conference proceedings, pilot studies
protocols, case studies, dissertations, and editorials were excluded.
Search strategies
In this review, searches were conducted on October 31st, 2024, with the support of a
health science librarian across four electronic databases: PubMed, CINAHL, Embase,
and IEEE Xplore (Institute of Electrical and Electronics Engineers). The core search
strategy focused on the concepts of ML and infant crying, combined with terms related
to classiﬁcation and pattern recognition. To ensure comprehensive coverage, additional
search terms included “machine learning” OR “deep learning” AND “infant cries”
AND “classiﬁcation” OR “pattern recognition” along with various commonly used
keywords (e.g. “convolutional neural network,” “support vector machine,” “newborn
cry,” and “baby cry”). The search terms were applied using database-speciﬁc search
methodologies
and
incorporated
Boolean
operators,
Medical
Subject
Headings
(MeSH), and free-text terms tailored to each database—using MeSH terms or title/
abstract searches for PubMed, CINAHL, and Embase, and IEEE Terms for IEEE
Xplore. For example, the MeSH term “machine learning” is used in various databases
as follows: in PubMed it appears as (“Machine learning"[mh]), in CINAHL as (MH
“Machine learning+”), in Embase as (“machine learning”/exp), and in IEEE as
(IEEE Terms: “Machine learning”). All databases were last searched on October
31st, 2024. The full search strategy is provided in Table S1 of the Supplemental
materials.
Selection process and data collection
All searched articles were imported to Rayyan (copyright © 2022), a web-based soft-
ware application tool for screening studies for systematic reviews, and duplicate stud-
ies were removed. Two reviewers (SS and NK) independently screened the articles
by title and abstract using a practical screening table developed from the inclusion
and exclusion criteria. This table served to guide the reviewer through the screening
process and minimize selection bias. Following this initial screening phase, the
selected articles were reviewed in full text to assess eligibility and relevance. The
articles that did not meet the eligibility criteria were excluded. Any disagreements
between the two reviewers were resolved through discussion. If the conﬂict was
not resolved through discussion, the reviewers will consult with a third opinion
(SN). This systematic process ensured that only relevant studies were included in
the further assessment.
Sirithepmontree et al.
5


---

Data extraction
Relevant data from the selected articles was extracted using a predeveloped data extrac-
tion form in Microsoft Excel. The main categories for data extraction include (1) General
characteristics: this includes information such as the authors and the year of publication,
the number of datasets, characteristics of the datasets, and sample size. (2) Performance:
this category includes the ML algorithms used as classiﬁers. (3) Outcomes: this includes
classiﬁcations of crying types and diagnostic performance metrics, speciﬁcally accuracy
rate (%), sensitivity (%), and speciﬁcity (%). The characteristics of the included studies
are presented in Table 2.
Quality assessment
Two reviewers (SS and NK) were assigned and independently assessed the quality of the
included studies by using the Quality Assessment of Diagnostic Accuracy Studies-2
(QUADAS-2) tool.30 This tool is designed for assessing the quality of primary diagnostic
accuracy studies in systematic reviews. The QUADAS-2 consists of four domains: (1)
patient selection, (2) index test, (3) reference standard, and (4) ﬂow and timing. Each
domain is assessed for risk of bias, and the ﬁrst three domains are also evaluated regard-
ing applicability. There are 10 questions for assessing the risk of bias aspect and three
questions for assessing the applicability. The results are reported as “low risk,” “high
risk,” and “unclear risk.”
For the interpretation of overall quality, if all questions within a domain are answered
“yes,” the study is judged as having a “low risk,” indicating that appropriate methods and
safeguards against bias were clearly reported. A study is considered “high risk” if at least
one question within the domain is answered “no,” reﬂecting evident methodological
ﬂaws. An “unclear risk” is assigned when the study provides insufﬁcient information
for a judgment.30 The detailed results of the quality assessment are provided in the
Supplemental materials.
Data analysis and synthesis
Data were extracted into an extraction form to tabulate and visually display the results
of each study. This review plans to categorize the results into three parts: (1) infant
cry type, (2) classiﬁer type, and (3) the accuracy of classiﬁcation. Moreover, a table
was created to show the infant cry type and the ML classiﬁers used in each study,
providing a clear visual representation of the different classiﬁer types. Another table
was created to provide the accuracy of classiﬁcation for each classiﬁer, helping to dis-
tinguish and synthesize evidence based on three main groups of ML models: super-
vised learning, unsupervised learning, and hybrid models.31 A narrative synthesis has
been used to describe the results of a systematic review. Additionally, a pie chart was
used to illustrate the proportion of physiological and pathological cry classiﬁcations
using ML.
6
Science Progress 109(1)


---

Results
Search overview results
Figure 1 illustrates the study selection process, which involved a total of 919 studies
identiﬁed across four databases. A total of 37 duplicate records were removed using
Rayyan. The remaining 882 studies to be reviewed based on their titles and abstracts.
There were 840 studies excluded due to not meeting the eligibility criteria. This pro-
cess resulted in 42 studies being retrieved for full-text review, and two studies32,33
were excluded due to unavailability of full text. As a result, 40 studies were assessed
for eligibility, and 23 studies were excluded for several reasons as described in the
PRISMA diagram in Figure 1. There were 17 included studies in this systematic
review.
Figure 1. PRISMA ﬂow diagram of the included studies.
Sirithepmontree et al.
7


---

Included study characteristics
The search yielded the ﬁnal 17 included studies that were cross-sectional study. The
publication years ranged from 2014 to 2024. For the infant cries dataset, 11
studies2–5,11,15,16,23,34–36 utilized self-recorded sounds, ﬁve studies12,24,37–39 relied on
public databases, and one study40 did not specify the source as shown in Table 2. In total,
there were around 113,677 infant cries, ranging between 300 and 54,744 sounds. For
the ML classiﬁers type, 13 studies2–5,11,15,23,34,36,37,39–41 used supervised learning, two
studies35,38 used unsupervised learning, and the remaining two studies12,24 used a hybrid
approach, which is detailed in Table 4. Ten studies2,3,11,12,15,16,34,35,37,40 reported on spe-
ciﬁc cry types related to infants’ needs, four studies4,5,23,36 focused on pathological cries,
and three studies24,38,39 addressed both categories.
The distribution of infant cry types is illustrated in Figure 2, which includes nine sub-
types. The hunger cry represented the largest proportion, accounting for 29%, followed
closely by the pain cry at 27%. Other notable types were the sleepy cry at 12%, the
Figure 2. The proportion of infants’ need cry types using machine learning classiﬁcation.
8
Science Progress 109(1)


---

discomfort cry at 10%, the wet diaper cry at 7%, and the burp and fussy cry at 5%. The
remaining cry types, holding and cold, constituted a smaller proportion of 3% and 2%,
respectively. In Figure 3, the distribution of pathological cry types was presented, divided
into six subtypes. The four most prevalent were the sepsis cry and respiratory distress cry,
both at 22%, followed by asphyxia at 21% and deafness at 21% as well. The smallest propor-
tions were hypoxic-ischemic encephalopathy (HIE) and asthma, each accounting for 7%.
Overview and comparison of existing infant cry databases
The infant cry database from the 17 included studies can be divided into two main types:
cry databases and self-recorded datasets. Five studies12,24,37–39 used cry databases, 11
studies used self-recorded datasets, and one study40 did not specify the dataset source.
To evaluate the quality and characteristics of the infant datasets used in this review,
each database and self-recorded dataset will be described in detail below.
Infant cry databases in this review include four main datasets: Donate a Cry Corpus,12
Baby Chillanto Infant Cry,12,24,38,39 Dunstan Baby,37 and In-House Dhirubhai Ambani
Institute of Information and Communication Technology (DA-IICT) Infant Cry.38
Figure 3. The proportion of pathological cry types using machine learning classiﬁcation.
Sirithepmontree et al.
9


---

Each database varies in the types of cries, the number of cry samples, and infant age
ranges. Donate a Cry Corpus42 demonstrates diversity across both cry contexts and infant
age, as it was developed through a crowdsourced mobile application that enabled global
parental participation. However, because it contains 457 audio ﬁles across ﬁve cry types:
belly pain, burping, discomfort, hungry, and tired from an unspeciﬁed number of infants
aged between 0 and 2 years, the lack of controlled recording environments and limited
identity tracking may introduce acoustic variability and background noise that can affect
feature extraction accuracy.43 Baby Chillanto Infant Cry Database44 was created by the
Instituto Nacional de Astrofísica, Óptica y Electrónica in Mexico under the
CONACYT program. This database provides medically supervised and structured data
collection. It contains 2268 audio recordings with ﬁve classes: asphyxia, deaf, normal,
hunger, and pain from newborns up to 6 months old, by specialized physicians under con-
trolled conditions. Although it ensures high acoustic quality, the dataset does not fully
specify the number of unique infants, limiting transparency into how many samples
were obtained per individual. Dunstan Baby45,46 was developed by Priscilla Dunstan
with her research team for commercial reasons. Dunstan had experience in opera and
as a mother, which allowed her to recognize speciﬁc sounds in the human voice. The
database contains infant cries from infants aged 6 months or younger in ﬁve types: hun-
gry, burp, sleepy, pain, and discomfort. Approximately 83 infant cries in the video were
recorded by 39 infants in a studio to eliminate noise. However, its small sample size
restricts the dataset’s variability and may lead to overﬁtting.47 In-House DA-IICT
Infant Cry was developed at the Dhirubhai Ambani Institute of Information and
Communication Technology in India for research purposes. It includes 1190 cry samples
in three categories: healthy, asthma, and HIE, but lacks documentation of the number of
participating infants and their ages. Overall, existing infant cry databases differ widely in
cry types, infant ages, and the number of recordings, reﬂecting diverse data collection
methods. However, most databases lack detailed information on infant identity and stan-
dardized labeling, which limits data transparency and comparability across studies.
The self-recorded datasets created by the authors in each study included a variety of
infant cry recordings that differed in several characteristics. The details of these datasets
are shown in Table 1, which summarizes three key aspects: infant identity control, record-
ing environment, and preprocessing procedures. For the infant identity control, all studies
reported the number of infants in the study, except for four studies.2,3,23,34 Additionally,
most studies did not specify how many cry samples were obtained from each infant; only
three studies4,23,35 reported this information. This indicates limited control over infant
identity and reduced transparency, as the use of multiple samples from the same infant
may lead the ML model to recognize the baby’s individual vocal characteristics rather
than the true acoustic features of different cry types. Likewise, only one study4 reported
the number of exemplars derived from each recording, which further limits transparency.
Without control, it is possible that multiple cry samples originated from the same record-
ing session or environment, causing the classiﬁer to rely on background or environmental
noise instead of the infant’s cry itself.48 To reduce this limitation, almost all studies,
except one,34 implemented some form of preprocessing to improve the quality of cry
recordings and minimize background interference, such as manual removal of noncry
10
Science Progress 109(1)


---

Table 1. Characteristics of self-recorded datasets: infant identity control, recording environment, and preprocessing methods.
Authors
Number of
infants
Number of cry
samples per
infant
Number of
exemplars per
recording
Training–
testing (%)
Recording
environment
Recording device
Noise control
Normalization or
segmentation
Zhang
et al.34
Not reported
Not reported
Not reported
90:10
The University
Malaya Medical
Centre,
Malaysia
Not reported
device
Not reported
Not reported
Laguna
et al.35
38 healthy
full-term
newborns
(21 males,
17 females)
4 cry episodes
Not reported
Not reported
Maternity ward in
the hospital
ZOOM H1N™
recorder (with
a unilateral
microphone)
Manual review
and software
inspection
(iZotope
RX7),
band-pass
ﬁlters
Normalization:
power spectral
density
Segmentation:
manually
segmented into
Cry Episodes
and Cry Units
Joshi et al.2
Not reported
Not reported
Not reported
80:20 (CNN);
75:25
(ensemble
models)
National Taiwan
University
Hospital
Sony HDR-PJ10
HD
computerized
video recorder
MFCC feature,
spectral
features, and
DropBlock
regularization
Batch normalization
segmentation:
framing and
windowing
Liang
et al.16
59 infants
Not reported
Not reported
70:15:15
(training:
validation:
testing)
The Far Eastern
Memorial
Hospital,
Taiwan
Lollipop baby
monitor
Preprocessing,
remove
sounds of
adults, other
infants,
mechanical/
electronic
noise
Segmentation: each
10-s audio clip
Ashwini
et al.3
Not reported
Not reported
Not reported
80:20
National Taiwan
University
Hospital Yunlin
Branch, Taiwan
Not reported
Not reported
Normalized
spectrogram
images;
short-time
Fourier-
transform
segmentation
(continued)
Sirithepmontree et al.
11


---

Table 1. Continued.
Authors
Number of
infants
Number of cry
samples per
infant
Number of
exemplars per
recording
Training–
testing (%)
Recording
environment
Recording device
Noise control
Normalization or
segmentation
Chang
et al.11
29 infants
(male: 17,
female: 12)
Not reported
Not reported
50:50
National Taiwan
University
Hospital Yunlin
Branch, Taiwan
Sony
HDR-PJ10 high
deﬁnition
camcorder
Inferences and
disturbances
existing in the
cry data were
eliminated
Normalization
performed as the
ﬁrst step of
preprocessing,
cry signals were
divided into
frames and
windows
Parga
et al.15
691 infants
Not reported
Not reported
Not reported
Natural
environments,
e.g. home or
clinic settings
Various devices,
primarily cell
phones
Secondary cry
detection
algorithm
screened out
noncry sounds
Cries were
segmented into
5-s utterances,
and
suprasegmental
features were
extracted using
OpenSmile for
standardization
Matikolaie
and
Tadj5
108 healthy
infants, 17
sepsis infants
Not reported
Not reported
70:30
Sainte-Justine in
Montréal
Hospital,
Canada,
Al-Sahel and
Al-Raee
Hospital,
Lebanon
WS-650M
Olympus digital
voice recorder
Noisy samples
were manually
ﬁltered out
Normalized using
preprocessing
and cry was
segmented into
three cry phases
(inspiration,
phonation,
expiration)
Zayed
et al.23
Not reported
Each infant’s
voice was
recorded
ﬁve times,
each session
lasting 90 s
Not reported
Not reported
Sainte-Justine in
Montréal
Hospital,
Canada,
Al-Sahel and
Al-Raee
Two-channel
Olympus
handheld
recorder
The
preprocessing
removed
background
noise, artifacts,
and silence
WaveSurfer
software was
used to perform
the
segmentation
process
(continued)
12
Science Progress 109(1)


---

Table 1. Continued.
Authors
Number of
infants
Number of cry
samples per
infant
Number of
exemplars per
recording
Training–
testing (%)
Recording
environment
Recording device
Noise control
Normalization or
segmentation
Hospital,
Lebanon
before
segmentation
Khalilzad
et al.4
17 sepsis
infants, 33
RDS infants
Each infant’s
voice was
recorded
ﬁve times,
and each
session had
an average of
90 s
53 recordings
from 17
sepsis
infants, 102
recordings
from 33 RDS
infants
55:15:30
(training:
validation:
testing)
Sainte-Justine in
Montréal
Hospital,
Canada,
Al-Sahel and
Al-Raee
Hospital,
Lebanon
Two-channel
Olympus
handheld
recorder
Preprocessing
included the
removal of
silence,
background
noise, and
artifacts
WaveSurfer
software was
used to perform
the
segmentation
process
Matikolaie
and
Tadj36
78 healthy
infants and
34 infants
with RDS
Not reported
Not reported
90:10
Sainte-Justine in
Montréal
Hospital,
Canada,
Al-Sahel and
Al-Raee
Hospital,
Lebanon
Two-channel
sound
recorder
Unwanted
episodes were
removed
during
preprocessing
Segmentation were
assigned using
WaveSurfer
software
CNN: convolutional neural network; HDR: high dynamic range; RDS: respiratory distress syndrome; MFCC: Mel-frequency cepstral coefﬁcient.
Sirithepmontree et al.
13


---

sounds, band-pass ﬁltering, or noise suppression algorithms. Overall, most datasets
demonstrated attention to noise reduction and preprocessing, which helped ensure that
classiﬁers primarily relied on acoustic features of the infant cry rather than environmental
or background noise (Table 2).
Infant cries type classiﬁcation
In a review of 17 included studies, infant cries were analyzed using ML and categorized
into two main types: infant’s need and pathological cries. Speciﬁc need cries or nonpatho-
logical include nine types of crying, such as hunger, sleepiness, pain or distress, wet dia-
per, discomfort, fussiness, the need to burp, a desire for holding or touch, and feeling
cold. Pathological cries include six types, such as sepsis, RDS, asphyxia, deafness,
asthma, and HIE. Tables 3 and 4 illustrate an overview of these cries, displaying the types
of crying, the ML classiﬁers used, and their performance rates. The two main categories
of crying are compared based on the classiﬁers utilized and their performance rates.
Infant-speciﬁc need cry type or nonpathological cry. The studies on infant-speciﬁc cry types
identiﬁed nine different types of crying that were classiﬁed using various classiﬁers. The
performance rate of this classiﬁcation varied signiﬁcantly depending on the classiﬁer
used. There were 12 studies2,3,11,12,15,16,24,35,37–40 focused on hungry cry, which was
the most commonly classiﬁed type. The accuracy of hungry cry classiﬁcations ranged
widely, with performance rates between 68.8% and 99.82%. The highest accuracy of
hunger cry was achieved at 99.82% by using a Gaussian mixture model (GMM). Five
studies2,3,11,35,37 utilized ML to classify sleepy cry, with accuracy ranging from 66.8%
to 95.69%. The best performance (95.69%) was achieved using a support vector machine
(SVM). From 11 studies2,3,12,15,16,24,34,3537–39 that mentioned pain cry, the performance
varied from 46.0% to 99.82%. The lowest performance rate was classiﬁed using an arti-
ﬁcial neural network (ANN), while the highest was classiﬁed by a GMM. For wet diaper
cry, three studies2,16,34 indicated that there was a performance rate ranging from 53.0% to
90.15%. Interestingly, both the highest and lowest performance rates were classiﬁed
using long short-term memory (LSTM), but they utilized different features. The highest
performance rate employed VGG16, while the lowest used Mel-frequency cepstral coef-
ﬁcients (MFCCs). Five studies3,11,12,37,40 reported high accuracy in discomfort cry clas-
siﬁcation, ranging from 86.1% to 97.34%, with SVM achieving the highest accuracy rate.
Additionally, two studies35,37 mentioned burp cry, which showed accuracy from 68.8%
to 92.1% that convolutional neural networks (CNNs) were found to be the most effective
classiﬁer. The other three speciﬁc needs cries of fussiness, a desire for holding, and feel-
ing cold, were reported by a different study with the best performance rates at 92.0%,35
59.0%,16 and 90.15%,34 respectively.
From the performance rate of each infant-speciﬁc cry type mentioned above, it is evi-
dent that different classiﬁers achieved the highest accuracy for each different cry type.
The best classiﬁers of each cry type were as follows: a GMM for hungry cries, an
ANN for pain cries, an LSTM for wet diaper cries, an SVM for discomfort cries, a
CNN for burp cries, and an acoustic multistage interpreter (AMSI) for fussiness. The cries
14
Science Progress 109(1)


---

Table 2. The characteristics of the included studies.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
Infants’ need cry classiﬁcation
Li et al.12
To develop a classiﬁcation model
using ResNet and a
transformer for analyzing
infant crying.
The number of cry datasets
is 5204 divided into
- Hunger: N = 2080
- Uncomfortable: N =
1760
- Pain: N = 1364
The number of training and
testing cry datasets: 80%
and 20%
The cry datasets were
received from three
databases
-
Donate a Cry Corpus
-
Chillanto
-
Environmental sound
classiﬁcation-50 (ESC-
50)
SE-ResNet-Transformer
(developed by adding
squeeze-and-
excitation (SE)
mechanism to the
residual blocks of
ResNet)
Feature extraction
(extracting key
acoustic
characteristics from
audio signals): MFCC
Three types of crying
classiﬁcation
-
Hungry
-
Uncomfortable
-
Pain
The percent accuracy
rate of each neural
network feature
- SE-ResNet-
Transformer: 93%
- SE-ResNet34: 92%
- ResNet18: 87%
- ResNet34: 88%
- ResNet50: 84%
- SE-ResNet50: 87%
Conclusion
The mixed MFCC
signiﬁcantly enhances the
model performance by
integrating the SE
mechanism into residual
blocks of ResNet.
Low
risk
Zhang et al.34
To develop a method that can
effectively minimize the
conﬂict among deep learning
models and improve the
accuracy of baby cry
recognition.
The number of cry datasets
is 1726, divided into
- Pain: N = 580
- Cold: N = 578
- Wet diaper: N = 578
The number of training and
testing cry datasets: 90%
and 10%
Pain cry was collected when
the baby was given an
injection, cold data was
collected when the baby
The cries of the infant
were recorded in the
University Malaya
Medical Centre,
Malaysia.
Classiﬁer: Long short-
term memory (LSTM)
Feature extraction:
VGG16
(The whale optimization
algorithm-variational
mode decomposition:
WOA-VMD was
integrated to
recognize infant cries)
Three types of crying
classiﬁcation
-
Pain
-
Cold
Percent of accuracy,
sensitivity, and F1-
score (the harmonic
mean of precision and
recall)
Accuracy: 90.15%
Sensitivity: 90.17%
F1-score: 90.22%
High
risk
(continued)
Sirithepmontree et al.
15


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
was showered with cold
water, and diaper change
data was collected when the
baby was suffering from a
wet diaper.
-
Wet diaper
Abbaskhah et
al.37
To determine three machine
learning classiﬁers: support
vector machine (SVM),
multilayer perceptron (MLP),
and convolutional neural
network (CNN) to classify
infant cry.
The number of cry datasets
is 315 divided into
- Hungry: N = 37
- Need to burp: N = 56
- Sleepy/tired: N = 61
- Stomach cramp
- (lower gas): N = 55
- Physical discomfort at
skin level (wet, hot):
N = 106
The number of training and
testing cry datasets:
- SVM: 85% and 15%
The number of training,
validation, and testing cry
datasets:
- MLP: 80, 10 and 10%
- CNN: 80, 10 and 10%
The cry datasets were
received from Dunstan
recorded databases
and have 44,100 Hz, up
to 1.5 s.
After feature extraction,
two types of data are
used
1.
Asymmetry data for
each class (non-
SMOTE)
2.
Symmetry data for
each class (SMOTE
method).
Three classiﬁers type
-
Support vector
machine (SVM)
-
Multilayer perceptron
(MLP)
-
Convolutional neural
network (CNN)
Feature extraction:
MFCC
Five types of crying
classiﬁcation
-
Hungry
-
Need to burp
-
Sleepy/tired
-
Stomach cramp
(lower gas)
-
Physical discomfort at
skin level (wet, hot)
Percent of accuracy rate
SVM
- Non-SMOTE: 82.3%
- SMOTE: 86.1%
MLP
- Non-SMOTE: 87.6%
- SMOTE: 89.2%
CNN
- Non-SMOTE: 92.1%
- SMOTE: 91.1%
Conclusion
The best classiﬁcation
accuracy of ﬁve classes is
reported using the CNN
model designed for non-
SMOTE data up to 92.1%
with 0.005 tolerance.
Low
risk
Aggarwal et
al.40
To develop a model for
recognizing baby cries and
distinguishing between
different kinds of baby cries.
The number of cry datasets
is 457, divided into
- Hungry: N = 282
- Discomfort: N = 175
Did not provide
information
Four classiﬁers type
-
Logistic regression
-
Support vector
machine
-
Decision tree
-
Random forest
Percent of accuracy,
sensitivity, and
speciﬁcity
Logistic regression
Hungry: 93.75, 94.09,
93.57%
Discomfort: 93.81, 93.88,
High
risk
(continued)
16
Science Progress 109(1)


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
Feature extraction:
spectrum
Two types of crying
classiﬁcation
-
Hungry
-
Discomfort
93.64%
Support vector
machine
Hungry: 97.12, 97.37,
96.86%
Discomfort: 97.34, 97.56,
97.06%
Decision tree
Hungry: 92.32, 92.22,
92.02%
Discomfort: 92.28, 92.11,
91.93%
Random forest
Hungry: 94.03, 94.17,
93.69%
Discomfort: 94.32, 94.51,
94.22%
Laguna et
al.35
1.
To characterize newborns’
cry sound based on
acoustic features,
neurophysiological, and
behavioral signals.
2.
To
determine
the
most
relevant features to classify
different crying reasons by
using machine learning.
3.
To
demonstrate
deep
learning approaches (AMSI)
for interpreting infant cries.
The number of cry datasets
is 513 divided into
- Hunger: N = 102
- Sleepy: N = 111
- Fussy: N = 101
- Burp: N = 95
- Distress: N = 104
The number of training and
testing cry datasets: 70%
and 30%
Labeling
Different cry types were
deﬁned as changes in the
Characteristics of
infants
-
38 healthy full-term
infants (21 males, 17
females)
-
Recording age 15.54 ±
21.46 days after birth
-
Birth weight 3132.91 ±
404.29 g.
Crying record
-
The cries of the infant
were recorded in the
maternity ward of the
Clínic of Barcelona
Four classiﬁers type
-
Random forest
-
Logistic regression
-
AdaBoost
-
Acoustic multistage
interpreter (AMSI)
Feature extraction:
spectrum
Five types of crying
classiﬁcation
-
Hunger
-
Sleepy
-
Fussy
-
Burp
The percent accuracy,
sensitivity, speciﬁcity,
and F score (a metric
that evaluates a
classiﬁcation model’s
accuracy)
- Random forest:
75.0, 63.7, 95.2, 60.0%
- Logistic regression:
68.8, 54.7, 94.1, 54.4%
- AdaBoost
77.1, 63.0, 95.5, 64.0%
- Acoustic multistage
interpreter (AMSI)
92.0, 75.4, 94.1, 75.5%
Low
risk
(continued)
Sirithepmontree et al.
17


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
newborn’s status generated
by different scenarios (i.e.
hunger, sleepiness,
fussiness, need to burp,
stress, pain, etc.) by staff.
Hospital, Switzerland,
by neonatologists.
-
The cries of the infant
were recorded by
placing the recorder
away 30 cm from the
infant’s mouth.
-
Sampling frequency of
48 kHz and 24-bit
- Distress
Conclusion
The acoustic multistage
interpreter (AMSI)
algorithm achieved the
highest accuracy rate of
92%.
Joshi et al.2
1.
To classify infant cry signals
by using the convolutional
neuron network (CNN):
VGG16 and YOLOv4.
2.
To
improve
the
performance of the model
by using ensemble-based
boosting algorithms.
The total number of cry
datasets is 68,430
divided into
The number of training:
testing samples for CNN
classiﬁcation
-
Sleep: N = 12,820:3205
-
Hunger: N =
12,980:3245
-
Pain: N = 14,740:3685
-
Diaper: N = 14,204:3551
The number of training:
testing samples for
ensemble-based boosting
algorithms
-
Sleep: N = 12,924:4308
-
Hunger: N =
14,517:4839
-
Pain: N = 14,115:4705
-
Diaper: N = 14,418:4806
Infants age: 1–10 days
Crying record
-
The cries of the infant
were recorded in a
supine position and
40 cm from the infant’s
mouth.
-
Record at National
Taiwan University
Hospital
Convolutional neuron
network (CNN):
VGG16 and YOLOv4
(convolutional neural
network variants)
Feature extraction: Mel-
frequency cepstral
coefﬁcients (MFCC)
Four types of crying
classiﬁcation
- Sleep
- Hunger
- Pain
- Diaper change
Percent of accuracy,
sensitivity, and
speciﬁcity
VGG16
-
Sleep: 84.5, 88, 85.6%
-
Hunger: 86.3, 93,
90.2%
-
Pain: 84.2, 86, 85.5%
-
Diaper: 77.8, 83, 81%
YOLOv4
-
Sleep: 87.8, 90, 83%
-
Hunger: 86.7, 92, 88%
-
Pain: 82.3, 85, 81%
-
Diaper: 75.6, 84, 79%
Ensemble-based
boosting algorithms
-
Sleep: 94.5, 88, 87%
-
Hunger: 96.3, 93, 89%
-
Pain: 91.2, 86, 80%
-
Diaper: 92.8, 83, 76%
Low
risk
(continued)
18
Science Progress 109(1)


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
Conclusion
CNN with ensemble-
based boosting
algorithms provides
more diagnostic
performance than a single
CNN.
Liang et al.16
To study using deep learning
algorithms: the artiﬁcial neural
network (ANN),
convolutional neural network
(CNN), and long short-term
memory (LSTM) to recognize
infants’ necessities cries.
The total number of cry
datasets is 1705 divided
into
- Hunger: N = 868
- Change diaper: N = 301
- Emotional needs
(holding/touch): N = 486
- Pain (medical treatment):
N = 50
The number of training,
validation, and testing cry
datasets:
70%, 15%, and 15%
The audio was recorded by
nurses and then noted the
cause of crying:
- Hunger: stop crying
when fed
- Diaper change: stop
crying after the diaper
change.
- Emotional needs: stop
crying when physical
touch/holding
Characteristics of
infants
-
59 infants
-
Infants age: 2–27 days
Crying record
-
The cries of the infant
were recorded at the
Far Eastern Memorial
Hospital, Taiwan, by
nurse
-
The cries of the infant
were recorded by
placing the recorder
away 30 cm from the
infant’s bed.
-
Sampling frequency of
8000 Hz, 16-bit.wav
ﬁles
Three classiﬁers type
-
Artiﬁcial neural
network (ANN)
-
Convolutional neural
network (CNN)
-
Long short-term
memory (LSTM)
Feature extraction: Mel-
frequency cepstral
coefﬁcients (MFCC)
Four types of crying
classiﬁcation
-
Hungry
-
Change diaper
-
Emotional needs
(holding/touch)
-
Pain (medical
treatment)
Percent of sensitivity
(after balanced data)
Artiﬁcial neural
network
- Hungry: 27%
- Change diaper: 46%
- Emotional needs: 37%
- Pain: 35%
Convolutional neural
network
- Hungry: 46%
- Change diaper: 53%
- Emotional needs: 59%
- Pain: 49%
Long short-term
memory
- Hungry: 36%
- Change diaper: 29%
- Emotional needs: 47%
- Pain: 35%
Conclusion
CNN demonstrated the
Low
risk
(continued)
Sirithepmontree et al.
19


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
- Pain: caused by invasive
medical treatment
highest sensitivity for
recognizing infant cries,
at around 46–59%.
Ashwini et
al.3
To improve the performance of
the infant cry classiﬁcation
model, features will be
extracted using a deep
learning technique (CNN),
classiﬁed with a machine
learning algorithm (SVM), and
compared with the SVM-
based kernel techniques.
The total number of cry
datasets is 300 divided
into
- Hunger: N = 100
- Sleepy: N = 100
- Pain: N = 100
The number of training and
testing cry datasets:
80% and 20%.
Characteristics of
infants
-
Infants age: 1–10 days
with no pathological
problems or
complications.
Crying record
-
The cries of the infant
were recorded at
National Taiwan
University Hospital
Yunlin Branch, Taiwan.
One classiﬁer type
-
Support vector
machine
(SVM) and compare with
the SVM-based kernel
techniques (radial basis
function (RBF), linear,
and polynomial)
Features extraction:
CNN-based feature
extraction
Three types of crying
classiﬁcation
-
Hungry
-
Sleepy
-
Pain
Percent average of
accuracy, sensitivity,
and speciﬁcity
SVM with radial basis
function
Accuracy: 92.59%
Sensitivity: 94.50%
Speciﬁcity: 89.35%
SVM with linear
Accuracy: 89.63%
Sensitivity: 92.25%
Speciﬁcity: 84.54%
SVM with polynomial
Accuracy: 91.11%
Sensitivity: 93.42%
Speciﬁcity: 87.02%
Conclusion
The SVM–RBF provides
the highest accuracy of
infant cry classiﬁcation
at 92.59%.
Low
risk
Chang et al.11
To develop an efﬁcient
classiﬁcation system for
infants’ cries classiﬁcation by
using gradient boosting
algorithms with a grouped-
support vector network
(SVM).
The total number of cry
datasets is 1002 divided
into
- Hunger: N = 372
- Sleepy: N = 258
- Discomfort: N = 372
Characteristics of
infants
-
29 infants (male: 17,
female: 12) with no
pathological
background
-
Infants age: 1–10 days
One classiﬁer type
-
Support vector
machine
(SVM) + gradient
boosting algorithms
Feature extraction: The
Percent of accuracy rate
- Hungry: 95.69%
- Sleepy: 93.02%
- Discomfort: 95.16%
Accuracy means: 95.16%
Low
risk
(continued)
20
Science Progress 109(1)


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
The number of training and
testing cry datasets: 50%
and 50%.
Crying record
-
The cries of the infant
were recorded at
National Taiwan
University Hospital
Yunlin Branch, Taiwan.
-
The infant’s arms were
in a neutral thumb
position.
-
The cries of the infant
were recorded by
placing the recorder
away 40 cm from the
infant’s mouth.
-
The lengths of
recorded infant cries
were between 10 and
60 s.
selected ﬁve features:
Peak, Pitch, MFCCs,
ΔMFCCs, and LPCC
from 12 features.
Three types of crying
classiﬁcation
-
Hungry
-
Sleepy
-
Discomfort
Conclusion
This method has a fast
recognition rate of 27 s in
the identiﬁcation of cries.
Parga et al.15
To use the algorithm to predict
the behavioral state of infants
and compare it with the colic
sound.
The total number of cry
datasets is 1071, divided
into
- Pain: N = 353
- Fussy: N = 171
- Hungry: N = 167
- Colic: N = 380
Labeling
Each audio was identiﬁed
with the meaning of cry by
two medical staff raters.
The cry was noted by
causing, such as a pain cry
Characteristics of
infants
-
691 infants (36%
female)
-
Infants age: 0–24
months (average age 3
months)
Crying record
Audio was recorded in
the infants’ natural
environments, e.g. home
or clinic settings, by
caregiver or staff.
One classiﬁer type
-
Random forest (RF)
Feature extraction:
MFCCs, and spectral
features
Three types of crying
classiﬁcation
-
Pain
-
Fussy
-
Hungry:
Percent of accuracy,
sensitivity, and
speciﬁcity
Accuracy: 71.5%
Sensitivity: 91%
Speciﬁcity: 68%
Conclusion
Random forest can
achieve 71.5%
accuracy in
discriminating infant
cry. Colic cry is
Low
risk
(continued)
Sirithepmontree et al.
21


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
was captured during two
painful stimuli (vaccinations,
ear-piercings)
predicted as a 73%
chance of a painful cry.
Infants’ pathological cry classiﬁcation
Matikolaie
and Tadj5
To develop an automatic
diagnostic system for identifying
septic infants from healthy
infants
The number of cry datasets
was separated ﬁve-fold
to ensure the validity of
the model and divided
into expiration (EXP)
and inspiration (INSV)
voice. (technique to
evaluate a model’s
performance by splitting
the dataset)
Fold one
- EXP (healthy:sepsis)
507:507
- INSV (healthy:sepsis)
140:140
Fold two
- EXP (healthy:sepsis)
517:517
- INSV (healthy:sepsis)
141:141
Fold three
- EXP (healthy:sepsis)
524:524
- INSV (healthy:sepsis)
139:139
Characteristics of
infants
-
Infants age: 1–53 days
-
108 healthy infants, and
17 sepsis infants
Crying record
-
The cries of the infant
were recorded by staff
at two hospitals
1.
Sainte-Justine
in
Montréal
Hospital, Canada
2.
Al-Sahel and
Al-Raee Hospital,
Lebanon
-
The cries of the infant
were recorded by
placing the recorder
away from the infant
10–30 cm and
maintaining the
surrounding noise at a
minimum level.
Three classiﬁers types
-
Support vector
machine (SVM)
-
Decision tree
algorithm
-
Discriminant analysis
algorithm
Features extraction:
MFCC, tilt, intensity,
rhythm
Two types of crying
classiﬁcation
-
Healthy
-
Sepsis
Inspiration voice
The classiﬁer’s best F-
score results (a metric
that evaluates a
classiﬁcation model’s
accuracy)
- Cubic SVM (MFCCs):
85.70%
- Boosted tree (tilt):
79.00%
- Cubic SVM (intensity):
70.90%
- Cubic SVM (rhythm):
75.60%
- Quadratic SVM:
86.00%
Expiration voice
The classiﬁer’s best F-
score results
- Quadratic
discriminant (MFCCs):
83.00%
- Quadratic
discriminant (Tilt):
83.90%
- Cubic SVM (intensity):
74.60%
Low
risk
(continued)
22
Science Progress 109(1)


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
Fold four
- EXP (healthy:sepsis)
523:523
- INSV (healthy:sepsis)
132:132
Fold ﬁve
- EXP (healthy:sepsis)
453:453
- INSV (healthy:sepsis)
109:109
Labeling
Pediatricians labeled the
cries as healthy or septic
through the infants’ medical
examination.
- Quadratic
discriminant (rhythm):
77.70%
- Quadratic
discriminant: 82.80%
Conclusion
Feature sets using
quadratic SVM resulted in
the best F-score with
86% for the expiration
dataset and tilt feature
set with quadratic
discriminant resulted in
the best F-score of
83.90% for inspiration.
Patil et al.38
To enhance infant cry
classiﬁcation accuracy by
developing constant-Q
cepstral coefﬁcients (CQCC)
The total number of cry
datasets is 3458,
consisting of
Baby Chillanto database
- Healthy cry: normal N =
507, hungry N = 350,
pain N = 192
- Pathological cry
Asphyxia N = 340, deaf N =
879
In-House DA-IICT
database
- Healthy cry N = 793
The cry datasets were
received from two
databases
1.
The Baby Chillanto
infant cry database,
Mexico
2.
The In-House DA-
IICT infant cry
database, India
Two classiﬁers type
-
Gaussian mixture
model (GMM)
-
Support vector
machine (SVM)
Features extraction:
MFCC, LFCC, cepstral,
CQCC
Seven types of crying
classiﬁcation
-
Normal
-
Hungry
-
Pain
-
Asphyxia
Percent of the best
accuracy rate
Gaussian mixture
model
MFCC: 98.55%
LFCC: 98.25%
Cepstral: 98.68%
CQCC: 99.82%
Support vector
machine
MFCC: 88.11%
LFCC: 80.18%
Cepstral: 80.62%
CQCC: 91.19%
Low
risk
(continued)
Sirithepmontree et al.
23


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
- Pathological cry: asthma
N = 182,
Hypoxic-ischemic
encephalopathy (HIE) N =
215
-
Deaf
-
Asthma
-
HIE
Conclusion
The CQCC–GMM model
achieved the highest
accuracy of 99.82% in
classifying infant cries.
Zayed et al.23
To develop a medical diagnostic
system for interpreting
infants’ cry audio signals
(CAS) using a combination of
different audio domain
features and deep learning
(DL) algorithms for early
diagnosis.
The number of cry datasets
is 15,950 divided into
- Sepsis: N = 2554
- RDS: N = 4396
- Healthy: N = 9000
Labeling
Medical staff label the cry
based on medical tests and
reports that identify each
infant’s pathology (RDS,
sepsis)
Infants age: 1–53 days
Weight: 0.98 to 5.2 kg
Crying record
-
The cries of the infant
were recorded by staff
at two hospitals
1.
Sainte-Justine
in
Montréal
Hospital, Canada
2.
Al-Sahel and Al-
Raee Hospital,
Lebanon
-
The cries of the infant
were recorded by
placing the recorder
away 10–30 cm from
the infant with 16-bit
resolution and
44,100 Hz frequency.
-
Average duration of
recording 90 s
Three classiﬁers type
-
Random forest (RF)
-
Support vector
machine (SVM)
-
Deep neural network
(DNN)
Three features
extraction model
-
Harmonic ratio (HR)
-
Gammatone
frequency cepstral
coefﬁcients (GFCCs)
-
Image-based features
through the
spectrogram
Three types of crying
classiﬁcation
-
Sepsis
-
RDS
-
Healthy
Random forest (RF)
with GFCC and HR
Accuracy: 91.18%
Sensitivity and F1-score
rate:
- Sepsis: 89.00, 90.46%
- RDS: 93.00, 91.44%
- Healthy: 92.00,
92.46%
Support vector
machine (SVM) with
GFCC and HR
Accuracy: 94.79%
Sensitivity and F1-score
rate:
- Sepsis: 92.00, 93.97%
- RDS: 92.00, 92.68%
- Healthy: 97.00,
96.48%
Deep neural network
(DNN) with
Spectrogram HR and
GRCC
Accuracy: 97.50%
Low
risk
(continued)
24
Science Progress 109(1)


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
sensitivity and F1-score
rate:
- Sepsis: 96.00, 96.48%
- RDS: 97.00, 97.00%
- Healthy: 99.00,
98.49%
Conclusion
The highest accuracy
model to diagnose infant
cries is the deep neural
network (DNN) with
spectrogram, HR, and
GRCC features at
97.50%.
Zhang et al.39
To improve the performance of
the infant cry classiﬁcation by
combining the fusion feature
(BCRNet model) to compare
with the deep learning model.
The total number of cry
datasets is 2268, divided
into three datasets
1.
Asphyxia vs. normal,
hungry
-
Asphyxia: N = 340
-
Normal and hungry:
N = 507
2.
Deaf vs. normal and
hungry
-
Deaf: N = 879
-
Normal and hungry:
N = 507
3.
Hungry vs. pain
-
Hungry: N = 350
-
Pain: N = 192
The cry datasets were
received from the Baby
Chillanto Infant Cry.
Four classiﬁers type
-
Support vector
machine (SVM)
-
Deep neural network
(DNN)
-
Convolutional neural
network (CNN)
-
BCRNet model
Three features
extraction
-
Hybrid features
(MFCC, LMS, ZCR)
-
Spectrogram (STFT)
-
Fusion feature
(VGG16 and
ResNet50)
Percent of the best
accuracy and
sensitivity
Support vector
machine
Accuracy: 91.80%
Sensitivity: 87.02%
Deep neural network
Accuracy: 92.42%
Sensitivity: 87.94%
Convolutional neural
network
Accuracy: 92.77%
Sensitivity: 90.14%
BCRNet model
Accuracy: 96.96%
Sensitivity: 93.05%
Low
risk
(continued)
Sirithepmontree et al.
25


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
Five types of crying
classiﬁcation
-
Asphyxia
-
Deaf
-
Hungry
-
Pain
-
Normal
Conclusion
The BCRNet model
(fusion feature) has
more effectively
improved the accuracy
of baby cry
recognition compared
to other models.
Khalilzad et
al.4
To identify septic and respiratory
distress syndrome (RDS)
newborns by comparing the
machine learning between
multilayer perceptron (MLP)
and support vector machine
(SVM)
The number of cry datasets:
N = 2264 divided into
- Sepsis: N = 1132
- RDS: N = 1132
The number of training,
validation, and testing cry
datasets:
55%, 15%, and 30%
Labeling
The cry signals were labeled
as healthy or with the
diagnosed pathology group
based on medical reports by
staff.
Characteristics of
infants
-
Infants age: 1–53 days
-
17 sepsis infants, 33
RDS infants
-
Full term
Crying record
-
The cries of the infant
were recorded by staff
at two hospitals
1.
Sainte-Justine
in
Montréal
Hospital, Canada
2.
Al-Sahel and Al-
Raee Hospital,
Lebanon
-
The cries of the infant
were recorded by
placing the recorder
away 10–30 cm from
the infant with 16-bit
resolution and
44,100 Hz frequency.
Two classiﬁer types
-
Multilayer perceptron
(MLP)
-
Support vector
machine (SVM)
Two-feature extraction
model
-
Gammatone
frequency cepstral
coefﬁcients (GFCCs)
-
Harmonic ratio (HR)
Two types of crying
classiﬁcation
-
Septic
-
Respiratory distress
syndrome (RDS)
The percent accuracy,
speciﬁcity, and F score
(a metric that
evaluates a
classiﬁcation model’s
accuracy)
Multilayer perceptron
(MLP)
- GFCC: 88.51, 89, 89%
- HR: N/A
Support vector
machine (SVM)
- GFCC: 92.94, 93, 93%
- HR: 71.03, 71, 71%
Combine features
Multilayer perceptron
(MLP)
- GFCC + HR: 92.49,
92, 92%
Support vector
machine (SVM)
Low
risk
(continued)
26
Science Progress 109(1)


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
- GFCC + HR: 95.29,
95, 95%
Conclusion
The highest accuracy
model to identify septic
and RDS newborns is a
support vector machine
with GFCC + HR
features at 95.29%.
Matikolaie
and Tadj36
To provide a better classiﬁcation
performance for
differentiating the infant cry
between healthy and RDS
infants by using short-term
features and long-term
features.
The total number of cry
datasets is 376, divided
into
- Expiration dataset N =
191
- Inspiration dataset N =
185
The number of training and
testing cry datasets: 90%
and 10%.
Labeling
Medical experts at both
hospitals annotated the
cause of crying based on
medical reports.
Characteristics of
infants
-
117 full-term infants
(78 healthy infants and
34 infants with RDS)
-
Infants age: 1–53 days
Crying record
-
The cries of the infant
were recorded at two
hospitals
1.
Sainte-Justine
in
Montréal
Hospital, Canada
2.
Al-Sahel and Al-
Raee Hospital,
Lebanon
-
The cries of the infant
were recorded by
placing the recorder
away 10–30 cm from
the infant with 16-bit
resolution and
44.1 kHz frequency.
One classiﬁer type
-
Support vector
machine (SVM)
Six features extraction
-
MFCC
-
Tilt
-
Rhythm
-
MFCC + tilt
-
MFCC + rhythm
-
MFCC + tilt + rhythm
Two types of crying
classiﬁcation
-
Respiratory distress
syndrome (RDS)
-
Healthy
The percent accuracy and
sensitivity
Expiration dataset
- MFCC: 70.60, 43.00%
- Tilt: 55.50, 63.40%
- Rhythm: 44.50,
35.50%
- MFCC + Tilt: 73.30,
60.20%
- MFCC + Rhythm:
72.20, 46.20%
- MFCC + Tilt +
Rhythm: 73.80,
60.20%
Inspiration dataset
- MFCC: 65.10, 36.60%
- Tilt: 60.70, 71.10%
- Rhythm: 50.90,
32.20%
- MFCC + Tilt: 68.40,
43.00%
- MFCC + Rhythm:
63.70, 32.20%
Low
risk
(continued)
Sirithepmontree et al.
27


---

Table 2. Continued.
Authors,
year
Purpose
The number of datasets
Characteristics of dataset
and sample
Classiﬁer, crying type
classiﬁcation
Diagnostic performance
(%)
Study
quality
-
The length of each
record is within 2
−3 min.
-
The cause of crying,
including hunger, pain,
birth, wet diaper, etc.,
was annotated by
medical experts at
both hospitals.
- MFCC + Tilt +
Rhythm: 67.80,
41.10%
Conclusion
The best performance for
differentiating the infant
cry between healthy and
RDS infants is the
combination of all three
feature sets in the
expiration episode.
Rosales-
Pérez et
al.24
To improve the predictive
accuracy of infant cries to
differentiate between normal
and pathological cries.
The total number of cry
datasets is 2268, divided
into three datasets
1.
Asphyxia vs. normal,
hungry
-
Asphyxia: N = 340
-
Normal and hungry:
N = 507
2.
Deaf vs. normal and
hungry
-
Deaf: N = 879
-
Normal and hungry:
N = 507
3.
Hungry vs. pain
-
Hungry: N = 350
-
Pain: N = 192
-
The cry datasets were
received from the Baby
Chillanto Infant Cry
property of INAOE-
CONACyT, Mexico.
-
The infant’s cries were
recorded by medical
doctors and labeled
the reason for each
crying.
One classiﬁer type
-
Genetic selection of a
fuzzy model (GSFM)
algorithm
Features extraction: Mel-
frequency cepstral
coefﬁcient (MFCC) and
Linear predictive coding
(LPC)
Five types of crying
classiﬁcation
-
Asphyxia
-
Deaf
-
Hungry
-
Pain
-
Normal
The percent of accuracy
and sensitivity
Asphyxia vs. normal
and hungry
- Accuracy: 90.68%
- Sensitivity: 85.29%
Deaf vs. normal and
hungry
- Accuracy: 99.42%
- Sensitivity: 100%
Hungry vs. pain
- Accuracy: 97.96%
- Sensitivity: 99.43%
Low
risk
AdaBoost: adaptive boosting; AMSI: acoustic multistage interpreter; BCRNet model: bidirectional convolutional recurrent network; Classiﬁer: the extracted features to
categorize data into classes; CNN: convolutional neural network; Feature extraction: extracting key acoustic characteristics from audio signals; F-score results: a metric that
evaluates a classiﬁcation model’s accuracy; GMM: Gaussian mixture model; LFCC: linear frequency cepstral coefﬁcients; LMS: least mean squares; LPCC: linear predictive cepstral
coefﬁcient; MFCC: Mel-frequency cepstral coefﬁcients; MLP: multilayer perceptron; ResNet: residual network; SE-ResNet-transformer: squeeze-and-excitation residual
network with transformer module; SVM: support vector machine; VGG: visual geometry group; WOA-VMD: whale optimization algorithm-variational mode decomposition;
ZCR: zero-crossing rate.
28
Science Progress 109(1)


---

Table 3. Infant cries type classiﬁcation and machine learning classiﬁer.
Authors
Speciﬁc need cry classiﬁcation
Pathological cry classiﬁcation
Classiﬁers
Features extraction
Hungry
Sleepy
Pain/
distress
Wet
diaper
Discomfort
Fussy
Burp
Holding/
touch
Cold
Sepsis
RDS
Asphyxia
Deaf
Asthma
HIE
Li et al.12
✓
✓
✓
SE-ResNet-transformer
MFCC
Zhang et al.34
✓
✓
✓
LSTM
VGG16
Abbaskhah et
al.37
✓
✓
✓
✓
✓
-
Support vector
machine (SVM)
-
Multilayer perceptron
(MLP)
-
Convolutional neural
network
Mel-frequency cepstral
coefﬁcients (MFCC)
Aggarwal et
al.40
✓
✓
-
Logistic regression
-
Support vector
machine (SVM)
-
Decision tree
-
Random forest
Spectrum
Laguna et al.35
✓
✓
✓
✓
✓
-
Random Forest
-
Logistic Regression
-
AdaBoost
-
Acoustic multistage
interpreter
Spectrum
Joshi et al.2
✓
✓
✓
✓
Convolutional neuron
network (CNN)
MFCC
Liang et al.16
✓
✓
✓
✓
-
Artiﬁcial neural
network (ANN)
-
Convolutional neural
network
-
Long short-term
memory (LSTM)
Mel-frequency cepstral
coefﬁcients (MFCC)
Ashwini et al.3
✓
✓
✓
Support vector machine
(SVM)
CNN-based
Chang et al.11
✓
✓
✓
Support vector machine
(SVM)
Peak, Pitch, MFCCs, ΔMFCCs,
and LPCC from 12
features
Parga et al.15
✓
✓
✓
Random forest
MFCC, spectrum
Matikolaie and
Tadj5
✓
-
Support vector
machine (SVM)
-
Decision tree
MFCC, tilt, intensity, rhythm
(continued)
Sirithepmontree et al.
29


---

Table 3. Continued.
Authors
Speciﬁc need cry classiﬁcation
Pathological cry classiﬁcation
Classiﬁers
Features extraction
Hungry
Sleepy
Pain/
distress
Wet
diaper
Discomfort
Fussy
Burp
Holding/
touch
Cold
Sepsis
RDS
Asphyxia
Deaf
Asthma
HIE
-
Discriminant analysis
Patil et al.38
✓
✓
✓
✓
✓
✓
-
Gaussian mixture
model (GMM)
-
Support vector
machine (SVM)
MFCC, LFCC, Cepstral,
CQCC
Zayed et al.23
✓
✓
-
Random forest
-
Support vector
machine (SVM)
-
Deep neural network
(DNN)
HR, GFCCs, spectrogram
Zhang et al.39
✓
✓
✓
✓
-
Support vector
machine (SVM)
-
Deep neural network
(DNN)
-
Convolutional neural
network
-
BCRNet model
Hybrid features (MFCC, LMS,
ZCR),
Spectrogram,
Fusion feature (VGG16 +
ResNet50)
Khalilzad et
al.4
✓
✓
-
Multilayer perceptron
(MLP)
-
Support vector
machine (SVM)
GFCCs, HR
Matikolaie and
Tadj36
✓
Support Vector Machine
(SVM)
MFCC, tilt, rhythm
Rosales-Pérez
et al.24
✓
✓
✓
✓
Genetic selection of a
fuzzy model (GSFM)
MFCC, linear predictive
coding (LPC)
AdaBoost: adaptive boosting; BCRNet model: bidirectional convolutional recurrent network; Classiﬁer: the extracted features to categorize data into classes; CQCC: constant-Q cepstral coefﬁcients; Feature extraction:
extracting key acoustic characteristics from audio signals; GFCC: gammatone frequency cepstral coefﬁcient; HIE: hypoxic-ischemic encephalopathy; HR: harmonic ratio; LFCC: linear frequency cepstral coefﬁcient; LMS:
least mean squares; LPCC: linear predictive cepstral coefﬁcient; LSTM: long short-term memory; ResNet: residual network; RDS: respiratory distress syndrome; SE-ResNet-transformer: squeeze-and-excitation residual
network with transformer module; VGG: visual geometry group; ZCR: zero-crossing rate.
30
Science Progress 109(1)


---

Table 4. Machine learning classiﬁer types and performance rate.
Authors
Supervised learning
Unsupervised
Hybrid
Classiﬁers compare
with performance rate
Best performance rate
SVM
Regression
Decision
Tree
RF
AdaBoost
MLP
CNN
ANN
LSTM
DNN
Discriminant
BCRNet
GMM
AMSI
SE-ResNet-
transformer
GSFM
Accuracy
(%)
Sensitivity
(%)
Speciﬁcity
(%)
F1-
Score
(%)
Li et al.12
✓
-
SE-ResNet-
transformer
93
93
-
92
Zhang et al.34
✓
-
LSTM
90.15
90.17
-
90.22
Abbaskhah et
al.37
✓
✓
✓
-
SVM
-
MLP
-
CNN
86.1
89.2
92.1
-
-
-
Aggarwal et
al.40
✓
✓
✓
✓
-
Regression
-
SVM
-
Decision tree
-
Random forest
93.81
97.34
92.32
94.32
94.09
97.56
92.22
94.51
93.64
97.06
92.02
94.22
-
Laguna et al.35
✓
✓
✓
✓
-
RF
-
Regression
-
AdaBoost
-
AMSI
75.0
68.8
77.1
92.0
63.7
54.7
63.0
75.4
95.2
94.1
95.5
94.1
60.0
54.4
64.0
75.5
Joshi et al.2
✓
-
CNN
77.8–86.3
83–93
81–90.2
-
Liang et al.16
✓
✓
✓
-
ANN
-
CNN
-
LSTM
-
46
59
47
-
-
Ashwini et
al.3
✓
-
SVM
92.59
94.50
89.35
-
Chang et al.11
✓
-
SVM
95.69
-
-
-
Parga et al.15
✓
-
Random forest
71.50
91
68
-
Matikolaie
and Tadj5
✓
✓
✓
-
SVM
-
Decision tree
-
Discriminant
85.00
78.30
78.80
-
-
86.00
79.00
83.90
Patil et al.38
✓
✓
-
GMM
-
SVM
99.82
91.19
-
-
-
Zayed et al.23
✓
✓
✓
-
Random forest
-
SVM
-
DNN
91.18
94.79
97.50
93
97
99
-
92.46
96.48
98.49
Zhang et al.39
✓
✓
✓
✓
-
SVM
-
DNN
-
CNN
-
BCRNet
91.80
92.42
92.77
96.96
87.02
87.94
90.14
93.05
-
-
Khalilzad et
al.4
✓
✓
-
MLP
-
SVM
-
Combine feature
88.51
71.03–
92.94
95.29
-
89
71–93
95
89
71–93
95
Matikolaie
and
Tadj36
✓
-
SVM
44.50–
73.80
32.2–71.1
-
-
Rosales-Pérez
et al.24
✓
-
GSFM
99.42
100
-
-
AdaBoost: adaptive boosting; AMSI: acoustic multistage interpreter; ANN: artiﬁcial neural network; BCRNet model: bidirectional convolutional recurrent network; CNN: convolutional neural network; DNN: deep neural network; GMM: Gaussian mixture model;
GSFM: genetic selection of a fuzzy model; LSTM: long short-term memory; MLP: multilayer perceptron; RF: random forest; SE-ResNet-transformer: squeeze-and-excitation residual network with transformer module; Supervised learning: the model is trained on
labeled data (inputs with known outputs); SVM: support vector machine; Unsupervised: the model is trained on unlabeled data.
Sirithepmontree et al.
31


---

associated with a desire for holding or touch and feeling cold did not have a classiﬁer
for comparing accuracy rates. However, the cries indicating feeling cold achieved
high accuracy rates when using an LSTM classiﬁer. In contrast, the cries expressing a
need for holding or touch had lower accuracy when employed with CNNs. It can be con-
cluded that the best accuracy rate for classifying nonpathological cries was observed for
hunger and pain cries, both reaching an impressive 99.82% accuracy by using a GMM
classiﬁer.
Pathological cry type. In this review, there were seven studies focused on pathological cry
types, which can be classiﬁed into six distinct types using various classiﬁers. There were
three studies4,5,16 focused on sepsis cry, revealing performance rates, ranging from
71.03% to 97.50%. Notably, a deep neural network (DNN) achieved the highest perform-
ance rate within this range. Three studies4,23,36 mentioned RDS cry and reported that clas-
siﬁcation accuracy varied signiﬁcantly, from 44.50% to 97.50%. The highest accuracy
was achieved using a DNN, while the lowest accuracy was noted with an SVM. Three
studies24,38,39 reported ﬁndings for both asphyxia and deafness cries, revealing high
accuracy rates. For asphyxia cries, accuracy ranged from 90.68% to 99.82%, while the
accuracy for deaf cries was even higher, ranging from 99.42% to 99.82%.
Furthermore, a GMM achieved the highest accuracy for both asphyxia and deaf cries.
Other pathological cries, such as asthma and HIE, were reported in one study,38 with per-
formance rates ranging from 91.19% to 99.82%, where GMM achieved the highest
accuracy.
From the performance rate of pathological cries mentioned above, it is evident that two
classiﬁers stood out for their high classiﬁcation accuracy: a DNN and a GMM. A DNN
was particularly effective in detecting sepsis and RDS cries. In contrast, a GMM exceled
in identifying cries linked to asphyxia, deafness, asthma, and HIE. Notably, the highest
accuracy rate for classifying pathological cries was observed for deafness, ranging from
99.42% to 99.82% accuracy by using a GMM classiﬁer.
ML classiﬁer
Performance rate across classiﬁer types. The most commonly used type of classiﬁer for
analyzing infant cries is supervised learning, with SVM being the most frequently utilized
classiﬁer. SVM has been employed in 10 out of 17 studies and showed a wide accuracy
range from 44.50% to 97.34%, indicating high sensitivity to feature quality and combin-
ation. Among these, eight studies3,5,11,2337–40 achieved high-performance rates ranging
from 85.00% to 97.34%. Five3,11,23,38,39 of these eight studies achieved high performance
when multiple acoustic features were combined. For example, Chang et al.11 achieved
95.69% accuracy using a combination of peak, pitch, MFCCs, ΔMFCCs, and linear pre-
dictive cepstral coefﬁcients, while Matikolaie and Tadj5 obtained 86% accuracy using
spectrum features alone. However, when limited to single or less informative features,
SVM performance decreased substantially. Two studies4,5 employed SVM as a classiﬁer
and reported medium- and low-performance rates. For instance, the study by Khalilzad
et al.4 relied solely on harmonic ratio features, while the research by Matikolaie and
32
Science Progress 109(1)


---

Tadj36 focused on rhythm features, achieving accuracies of 71.03% and 44.50%, respect-
ively. These results demonstrate that SVM can perform very well when supported by
diverse, discriminative features, but lacks robustness when relying on narrow or low-
quality inputs.
Seven other studies2,12,15,16,24,34,35 did not use an SVM as a classiﬁer but instead
employed alternatives, such as CNNs, GMMs, LSTM, regression, random forest,
ANNs, and hybrid classiﬁers. Among these, CNN was the most commonly used for clas-
sifying infant cries. Four studies2,16,37,39 applied CNNs, but the performance levels var-
ied, ranging from below 70% to 92.77%. Two studies37,39 achieved high accuracy rates,
between 92.10% and 92.77%, while the other two studies reported medium accuracy (70–
90%)2 and low accuracy (less than 70%).16 The differences in performance can be attrib-
uted to the fact that the ﬁrst two studies,37,39 which achieved high accuracy, utilized high-
quality datasets with a large number of infant cries, and the sounds were labeled by expert
staff, nurses, or pediatricians who have experience to identify the meaning of infant cry.
Additionally, one study39 integrated advanced architectures such as a bidirectional con-
volutional recurrent network (BCRNet) model to enhance recognition. In contrast, CNN
models trained with single feature or smaller datasets yielded moderate (70–90%)2 or low
(<70%)16 accuracies. This pattern highlights the strong dependence of CNNs on both
dataset quality and architectural complexity.
Among all the classiﬁers, the GMM demonstrated the highest performance rate in rec-
ognizing infant cries at 99.82%.38 When comparing under the same feature conditions
(MFCC), GMM clearly outperformed SVM (98.55% vs. 70.60%), demonstrating its
superior capacity to model the probabilistic distribution of acoustic characteristics in
infant cries. Similarly, hybrid or ensemble-based classiﬁers also achieved excellent
results; for instance, genetic selection of a fuzzy model (GSFM; 99.42%)24 and
squeeze-and-excitation
residual
network
with
transformer
module
(SE-ResNet-transformer; 93%),12 suggesting that combining statistical and deep-learning
methods can yield near-optimal recognition accuracy.
Other classiﬁers, though less frequently applied, also showed promising results.
Random forest15,23,35,40 and regression models35,40 demonstrated moderate-to-high
accuracy (68.8–94.32%), with the best performances observed when integrated into
ensemble frameworks. ANNs reported 46% accuracy,16 while DNNs ranged from
92.42%39 to 97.50%,23 showing improvement as model depth increased. LSTM net-
works, which are designed to capture temporal dynamics, achieved up to 90.15% accur-
acy34 but performed modestly (47%)16 in studies with imbalanced datasets. These
ﬁndings suggest that temporal models, such as LSTM can be powerful but require exten-
sive data to realize the potential.
Overall, the comparative evidence across studies indicates that GMM consistently deli-
vers the highest classiﬁcation accuracy, followed closely by hybrid deep-learning architec-
tures (GSFM, SE-ResNet-transformer). SVM remains the most commonly used classiﬁer
and can achieve competitive accuracy when multiple features are combined, such as
MFCC, tilt, and rhythm yields better performance than using a single feature. Random forest
and DNN approaches offer reliable mid-to-high performance, while simpler models such as
basic ANNs or regression show moderate accuracy. In summary, integrating multifeature
Sirithepmontree et al.
33


---

fusion with advanced or hybrid classiﬁers yields the most robust and accurate recognition of
infant cries, whereas models using limited features tend to underperform.
Performance rate across datasets. In this review, the dataset came from two main types:
infant cry databases and self-recorded data. For the databases, the infant cry sounds
were recorded in hospitals or homes and labeled with the meaning of crying by doctors,
nurses, or experts in infant vocalizations. In contrast, self-recorded cries were primarily
recorded in hospitals, but many lacked clear labeling during the annotation process. To
ensure data quality across different sources, almost all datasets underwent a standardized
preprocessing. This involved removing noise, silence, segmenting, and standardizing
audio amplitude levels to minimize variability across datasets. Out of 17 studies exam-
ined, 11 studies used self-recorded infant cry sounds, ﬁve studies12,2437–39 relied on
cry databases, and one study40 did not specify the data source. To evaluate the accuracy
across the datasets, the performance rates of infant cries from both types were compared.
Data from 11 self-recorded studies showed a performance rate ranging from 44.50% to
97.50%. In contrast, the cry databases exhibited a higher performance rate between
86.1% and 99.82%. In a comparison of self-recorded and cry databases using the same
classiﬁer and features with SVM and MFCC features, the self-recorded dataset from
the study by Matikolaie and Tadj5 achieved a performance rate of 86.00%. In contrast,
the cry databases used in the study by Patil et al.38 achieved a higher performance rate
of 88.11%. Therefore, infant cries from cry databases tend to achieve slightly higher
accuracy compared to self-recorded datasets. This is because datasets from cry databases
undergo veriﬁcation, data validation, and preprocessing by experts (pediatricians and
nurses) with experience in interpreting infant cries and labeling the reason for crying
by cause, and applying appropriate actions to stop it. This process enhances the quality
of infant cries accuracy to understand the meaning behind the infant cries.
The comparison of the accuracy rate by the chance level across studies
When comparing the accuracy rates across studies, the chance level serves as a crucial
reference point for interpreting algorithmic performance. Chance level, determined by
the proportion of the majority class in each dataset, reﬂects the baseline accuracy that
a naive classiﬁer could achieve by always predicting the most frequent category.
Table 5 presents the chance level accuracy, reported accuracy in each study, and the
improvement above chance. From the included studies, chance levels varied, ranging
from 21.64% to 61.71% for need-based cry classiﬁcation and from 25.42% to 56.43%
for pathological cry classiﬁcation. Ten studies2,3,11,12,24,34,3537–39 demonstrated substan-
tial improvements above chance of more than 50%, indicating that their reported accur-
acies were meaningful beyond random or naive prediction. The highest improvements
were observed in studies by Patil et al.,38 which had more balanced datasets, resulting
in improvements ranging from 65.77% to 74.4%, and provided more robust evidence
of discriminative ability.
In contrast, ﬁve studies4,16,23,36,40 with high class imbalance (chance level greater than
50%), achieved high raw accuracies but relatively small improvements above chance,
34
Science Progress 109(1)


---

Table 5. The chance level accuracy, reported accuracy, and the improvement above chance.
Authors
The number of datasets
Dataset sources
Chance
level (%)
Reported
accuracy (%)
Improvement
above chance (%)
Infants’ need cry classiﬁcation
Li et al.12
The number of cry datasets is 5204,
divided into
- Hunger: N = 2080; Uncomfortable: N
= 1760; Pain: N = 1364
Three databases
Donate a Cry Corpus; Chillanto;
Environmental sound
classiﬁcation-50
39.97
93.00
53.03
Zhang et al.34
The number of cry datasets is 1726,
divided into
- Pain: N = 580; Cold: N = 578; Wet
diaper: N = 578
The cries of the infant were recorded
in the University Malaya Medical
Centre, Malaysia.
33.60
90.15
56.55
Abbaskhah
et al.37
The number of cry datasets is 315,
divided into
- Hungry: N = 37; Need to burp: N =
56; Sleepy/tired: N = 61; Stomach
cramp: N = 55; Physical discomfort at
skin level: N = 106
Dunstan recorded databases.
33.65
86.10–92.10
52.45–58.45
Aggarwal et
al.40
The number of cry datasets is 457,
divided into
- Hungry: N = 282; Discomfort: N =
175
Did not provide information.
61.71
92.32–97.34
30.61–35.63
Laguna et
al.35
The number of cry datasets is 513,
divided into
- Hunger: N = 102; Sleepy: N = 111;
Fussy: N = 101; Burp: N = 95;
Distress: N = 104
The cries of the infant were recorded
in the maternity ward of the Clínic
of Barcelona Hospital, Switzerland,
by neonatologists.
21.64
68.80–92.00
47.16–70.36
Joshi et al.2
The total number of cry datasets is
68,430, divided into
The cries of the infant were recorded
26.93
77.80–86.30
50.87–59.37
(continued)
Sirithepmontree et al.
35


---

Table 5. Continued.
Authors
The number of datasets
Dataset sources
Chance
level (%)
Reported
accuracy (%)
Improvement
above chance (%)
- Sleep: N = 16,025; Hunger: N =
16,225; Pain: N = 18,425; Diaper: N =
17,755
in the National Taiwan University
Hospital
Liang et al.16
The total number of cry datasets is
1705, divided into
- Hunger: N = 868; Change diaper: N =
301; Emotional needs (holding/
touch): N = 486; Pain (medical
treatment): N = 50
The cries of the infant were recorded
at the Far Eastern Memorial
Hospital, Taiwan, by nurse.
50.91
Not reported
accuracy
(sensitivity
reported)
-
Ashwini et
al.3
The total number of cry datasets is 300,
divided into
- Hunger: N = 100; Sleepy: N = 100;
Pain: N = 100
The cries of the infant were recorded
at National Taiwan University
Hospital Yunlin Branch, Taiwan.
33.33
92.59
59.26
Chang et
al.11
The total number of cry datasets is
1002, divided into
- Hunger: N = 372; Sleepy: N = 258;
Discomfort: N = 372
The cries of the infant were recorded
at National Taiwan University
Hospital Yunlin Branch, Taiwan.
37.13
95.69
58.56
Parga et al.15
The total number of cry datasets is
1071, divided into
- Pain: N = 353; Fussy: N = 171;
Hungry: N = 167
The cries of the infant were recorded
at the clinical setting and at home.
32.96
71.50
38.54
Infants’ pathological cry classiﬁcation
Matikolaie
and Tadj5
The number of cry datasets was
separated into ﬁve folds and divided
into expiration (EXP) and inspiration
The cries of the infant were recorded
by staff at two hospitals
39.52
78.30–85.00
38.78–45.48
(continued)
36
Science Progress 109(1)


---

Table 5. Continued.
Authors
The number of datasets
Dataset sources
Chance
level (%)
Reported
accuracy (%)
Improvement
above chance (%)
(INSV) between healthy and sepsis
voice
Fold one: EXP: 507:507; INSV:
140:140
Fold two: EXP: 517:517; INSV:
141:141
Fold three: EXP: 524:524; INSV:
139:139
Fold four: EXP: 523:523; INSV:
132:132
Fold ﬁve: EXP: 453:453; INSV:
109:109
1.
Sainte-Justine
in
Montréal
Hospital, Canada
2.
Al-Sahel and Al-Raee Hospital,
Lebanon
Patil et al.38
The total number of cry datasets is
3458, consisting of
Baby Chillanto Database
- Healthy cry: Normal N = 507, hungry
N = 350, pain = 192
- Pathological cry: Asphyxia N = 340,
deaf N = 879In-House DA-IICT
Database
- Healthy cry N = 793
- Pathological cry: Asthma N = 182,
HIE: N = 215
Two databases
1.
The Baby Chillanto infant cry
database, Mexico
2.
The In-House DA-IICT infant cry
database, India
25.42
91.19–99.82
65.77–74.4
Zayed et al.23
The total number of cry datasets is
15,950, divided into
- Sepsis: N = 2554; RDS: N = 4396;
Healthy: N = 9000
The cries of the infant were recorded
by staff at two hospitals
1.
Sainte-Justine
in
Montréal
Hospital, Canada
56.43
91.18–97.50
34.75–41.07
(continued)
Sirithepmontree et al.
37


---

Table 5. Continued.
Authors
The number of datasets
Dataset sources
Chance
level (%)
Reported
accuracy (%)
Improvement
above chance (%)
2.
Al-Sahel and Al-Raee Hospital,
Lebanon
Zhang et al.39
The total number of cry is 2268, divided
into three datasets
1.
Asphyxia vs. normal, hungry
- Asphyxia: N = 340; Normal and
hungry: N = 507
2.
Deaf vs. normal and hungry
- Deaf: N = 879; Normal and
hungry: N = 507
3.
Hungry vs. pain
- Hungry: N = 350; Pain: N = 192
Baby Chillanto Infant Cry database
38.76
91.80–96.96
53.04–58.2
Khalilzad et
al.4
The total number of cry datasets: N =
2264, divided into
- Sepsis: N = 1132
- RDS: N = 1132
The cries were recorded by staff at
two hospitals
1.
Sainte-Justine
in
Montréal
Hospital, Canada
2.
Al-Sahel and Al-Raee Hospital,
Lebanon
50
71.03–95.29
21.03–45.29
Matikolaie
and Tadj36
The total number of cry datasets is 376,
divided into
- Expiration dataset N = 191
- Inspiration dataset N = 185
The cries were recorded at two
hospitals
1.
Sainte-Justine
in
Montréal
Hospital, Canada
2.
Al-Sahel and Al-Raee Hospital,
Lebanon
50.80
44.50–73.80
-6.30–23.0
Rosales-
The total number of cry datasets is
2268, divided into
The cry datasets were received from
the Baby Chillanto Infant Cry
38.76
99.42
60.66
(continued)
38
Science Progress 109(1)


---

Table 5. Continued.
Authors
The number of datasets
Dataset sources
Chance
level (%)
Reported
accuracy (%)
Improvement
above chance (%)
Pérez et
al.24
1.
Asphyxia vs. normal, hungry
- Asphyxia: N = 340; Normal and
hungry: N = 507
2.
Deaf vs. normal and hungry
- Deaf: N = 879; Normal and
hungry: N = 507
3.
Hungry vs. pain
- Hungry: N = 350; Pain: N = 192
property of INAOE-CONACyT,
Mexico
RDS: respiratory distress syndrome; Chance level: The estimated accuracy based on the largest class proportion in each dataset.
Sirithepmontree et al.
39


---

which may overestimate the actual discriminative ability of the models. One study5
reported performances near or below chance level for subsets, indicating limited practical
utility. These ﬁndings emphasize that the direct comparison of raw accuracy across stud-
ies is limited. Future work should consistently report classiﬁcation performance relative
to the chance level to allow for meaningful cross-study comparisons.
Quality assessment results
The Quality Assessment of Diagnostic Accuracy Studies-230 was utilized to evaluate the
quality of the included studies, which can be divided into two parts: risk of bias assess-
ment and applicability. Overall, 15 studies were considered as low risk, while two stud-
ies34,40 were classiﬁed as high risk. In the risk of bias assessment within the selection
domain, 15 studies did not specify the process for the random selection of patients, result-
ing in an unclear risk. Furthermore, the two studies34,40 did not provide information about
patient characteristics, which was considered a high risk that threatened internal validity.
All 17 studies are considered to have a low risk in the index test, reference standard, and
ﬂow and timing domains. For the applicability assessment, 15 studies demonstrated a low
risk in the selection domain, while two studies34,40 had an unclear risk, which reduces
conﬁdence in generalizing the results to the population and poses a threat to external val-
idity. Regarding the index test and reference standard domains, all 17 studies had a low
risk, as they employed a strong process for measure validation. Therefore, the results can
be regarded as having high conﬁdence for generalization and application in classifying
infant cry types. A quality assessment of each study is provided in Table S2 of the
Supplemental materials (see Figures 4 and 5).
Discussion
This systematic review synthesizes ﬁndings from 17 studies on the application of ML to
classify infant cry types, as well as the accuracy of this classiﬁcation. The results revealed
that ML can differentiate between two main types of cries: infants’ needs cries and
Figure 4. Quality assessment results of risk of bias by domain in QUADAS-2. QUADAS-2:
Quality Assessment of Diagnostic Accuracy Studies-2.
40
Science Progress 109(1)


---

pathological cries. Various classiﬁers were employed for these cry types, with each being
suited to speciﬁc cry types and impacting performance rates differently. For speciﬁc-need
cries, the highest classiﬁcation accuracy achieved was 99.82%,38 with hunger and pain
cries being the most accurately classiﬁed types by using GMMs. In pathological cries,
GMMs also achieved the highest accuracy for detecting pathological cries related to deaf-
ness, which was the most accurately classiﬁed, ranging from 99.42% to 99.82%.38 The
results clearly show that GMMs can effectively classify both nonpathological and patho-
logical cries with a high accuracy. This ﬁnding is consistent with the research conducted
by Jebarani et al.,49 who used various ML classiﬁers, including GMMs, SVMs, and
K-means, to detect breast cancer by categorizing magnetic resonance images as either
cancerous or noncancerous. Their study indicated that GMMs achieved the best classiﬁ-
cation accuracy, reaching 93.80%. Additionally, Khlaiﬁet al.50 applied GMMs to classify
swallowing sounds and other sounds during food intake in adult patients recovering from
stroke, achieving an accuracy ranging from 85.57% to 95.94% in distinguishing swallow-
ing sounds. Therefore, GMMs are considered the best classiﬁer for classifying speciﬁc
conditions in both sound and image.
Nevertheless, an SVM was the most commonly used classiﬁer for both speciﬁc-need
and pathological cries; however, its performance rate varies depending on the features
used and requires multiple features to enhance its performance. When comparing
GMMs and SVMs using the same classiﬁer, it was found that GMMs consistently out-
performed SVMs. These results align with the ﬁndings of Sen et al.,51 who compared
the classiﬁcation performance of SVMs and GMMs in distinguishing between healthy
and pathological pulmonary conditions based on pulmonary sounds. Their study revealed
that GMMs achieved higher accuracy than SVMs in pulmonary sound classiﬁcation.
Therefore, it can be concluded that a GMM appears to be the best classiﬁer to classify
speciﬁc conditions.
Furthermore, dataset quality can affect the accuracy rate of infant cries classiﬁcation. It
was found that the infant cry databases have a higher accuracy of infant cries than self-
record datasets. These results are consistent with the ﬁndings of Ji et al.,52 who reviewed
infant cry analysis and observed that cry databases demonstrated higher accuracy com-
pared to self-recorded datasets. Speciﬁcally, infant cry databases achieved accuracy rates
Figure 5. Quality assessment results of applicability by domain in QUADAS-2. QUADAS-2:
Quality Assessment of Diagnostic Accuracy Studies-2.
Sirithepmontree et al.
41


---

ranging from 71.68% to 97.96%, whereas self-recorded datasets ranged from 62.1% to
91.58%. This difference is attributed to the fact that infant cry databases undergo a sound
validation process and are annotated by experts to accurately label the meanings of the
infant cries. The experts mentioned in the included studies refer to pediatricians and
nurses who have experience in identifying the causes of infant crying and applying appro-
priate actions to stop it.
The dataset used in this review comprises four main databases: Donate a Cry
Corpus,12 Baby Chillanto Infant Cry,12,24,38,39 Dunstan Baby,37 and In-House
DA-IICT Infant Cry.38 The Donate a Cry Corpus includes ﬁve cry types: belly pain, burp-
ing, discomfort, hunger, and tiredness. The Baby Chillanto dataset contains ﬁve types:
deaf, asphyxia, normal, hunger, and pain. The Dunstan Baby dataset includes hunger,
need for a burp, need to poop, discomfort, and sleepy. The In-House DA-IICT dataset
consists of three types: normal, asthma, and HIE. While these datasets provide valuable
resources for infant cry analysis, they also present potential biases. Several datasets are
imbalanced, with some cry types (e.g. hunger or discomfort) being overrepresented,
while others (e.g. asthma or HIE) are limited in size. This imbalance may reduce gener-
alizability, with models favoring frequent cry types. Future work should address this
through data augmentation, balanced sampling, present infant identity controls, or
broader collection of representative cry samples.
There are some inconsistencies regarding the age of infants that should be considered
when training and analyzing ML models. Some studies4,23,36 have indicated that newborns
aged 1 to 53 days begin to gain control over their vocalizations during this period. Before
this age, vocalizations are primarily regulated by independent biological rhythms and may
indicate the newborn’s health. Recent evidence from Lockhart-Bouron et al.13 suggests
that human infants gradually transition from producing mainly noisy and shrill cries to
more tonal and melodious cries from birth up to nearly 4 months of age, with no signiﬁcant
differences observed between sexes. This underscores the importance of exploring the
appropriate age of infants to be used in ML to enhance accuracy rates and facilitate broader
development in the future. Additionally, future research on infant cry analysis should aim
to develop a standard dataset that can be utilized globally as a gold standard.
The application of ML to identify and classify the meanings of infant crying is essen-
tial for enhancing real-world parenting support. Currently, numerous initiatives are
underway to integrate ML systems into mobile applications, facilitating their use in
everyday situations. A recent research conducted by Mekhﬁoui et al.53 presented ML
experiments that employed three models: CNNs, Wav2Vec 2.0, and DistilHuBERT, to
classify infant crying sounds into distinct categories, including hunger, discomfort, tired-
ness, and belly pain. The ﬁndings demonstrated that while all models exhibited com-
mendable performance, DistilHuBERT achieved the highest accuracy (86.95%)
compared with CNNs (83.93%) and Wav2Vec 2.0 (81.52%), along with the best overall
metrics. Due to its advantageous balance of high accuracy and low computational cost,
DistilHuBERT has been identiﬁed as the most effective model for real-time implementa-
tion on embedded systems and mobile applications. Future research should explore ways
to further improve the techniques tailored to real-world conditions and apply them to
mobile applications.
42
Science Progress 109(1)


---

Conclusion
ML has demonstrated signiﬁcant potential in classifying infant cries, effectively differen-
tiating between types of cries related to the infant’s needs and pathological cries. The
need-based cries have nine subtypes, while pathological cries are categorized into six
subtypes. Various classiﬁers have been employed to recognize the patterns in these cries.
The accuracy of recognizing infant cries varies depending on the ML classiﬁer and the
features used for analysis. According to the studies reviewed, the accuracy rates range
from 44.5% to 99.82%. Among the classiﬁers tested, the GMM achieved the highest per-
formance rates, reaching 99.82% accuracy for hunger and pain cries, and between
99.42% and 99.82% for deafness-related cries. These advancements indicate that ML
shows strong potential for accurately classifying infant cries and detecting pathologies.
This capability is crucial for healthcare and everyday life, as it supports the early detec-
tion of health issues and improves infant care. Future research should focus on develop-
ing diverse cry datasets to improve model generalizability, evaluating performance in
real-world settings, and integrating cry analysis with physiological signals to enhance
diagnostic accuracy.
Limitations
This systematic review excluded gray literature, such as conference proceedings, disserta-
tions, and editorials, and was limited to studies published in English. The exclusion also omit-
ted articles published in other languages or indexed in other databases, which may have
introduced publication bias. Among the included studies, there were issues with unclear
patient selection processes in the datasets, leading to an unclear risk of bias in the selection
domain. One study40 did not report the sources or characteristics of the infant’s cries, limiting
transparency. Additionally, the studies reviewed did not consider the baby’s identity, includ-
ing factors such as age, sex, height, and weight, nor did they account for how many infants
were recorded crying or how many sounds came from a single infant in their analysis of baby
cries. It is crucial to incorporate this information into classiﬁcation models to avoid issues like
overﬁtting, pseudoreplication, and the false inﬂation of recognition accuracy. For the com-
parison of the accuracy rate with the chance level, the ﬁndings highlight that a direct compari-
son of raw accuracy across studies can be misleading and reinforce the importance of
reporting performance relative to the chance level to enable meaningful cross-study compar-
isons. The heterogeneity of datasets, including differences in cry categories, class balance,
and recording environments, further limits the ability to directly compare algorithmic per-
formance. Future research should consistently report chance-level baselines, include balanced
datasets, and incorporate complementary metrics such as balanced accuracy, Cohen’s kappa,
or F1-score to better reﬂect actual model performance.
Implication
This systematic review can serve as a foundation for future research, which should
include subgroup analyses or meta-analyses to compare the performance of different
Sirithepmontree et al.
43


---

ML classiﬁers across various types of infant cries. Additionally, it should evaluate the accur-
acy and reliability of infant cry datasets from online databases to identify the most accurate
and standardized dataset. Establishing a globally recognized standard dataset for infant cries
could enhance the consistency and reliability of ML applications in this ﬁeld.
In a cultural issue application, there is a concern about applying infant cries to different
cultures. The study by Cornec et al.54 examined the perception of infant crying across
communities in the Democratic Republic of Congo, comparing it to analogous data
from French and British samples to assess the perception by adults across diverse cul-
tures. The ﬁndings revealed no signiﬁcant differences between Congolese and
European populations in the acoustic structure of babies’ cries. This ﬁnding is consistent
with the study by Gustafson et al.,55 which found no difference in crying between infants
born in a Mandarin Chinese-language environment and those born in an American
English-language environment. Therefore, based on the evidence, it is reasonable to
believe that ML can be applied to analyze infant crying across all cultures.
In clinical practice, ML can be applied to the early detection of infant conditions
and the monitoring of infant health through cry analysis, enabling doctors and medical
staff to promptly identify potential diseases. For example, ML systems can assist
healthcare professionals in recognizing abnormal crying linked to speciﬁc medical con-
ditions, such as asphyxia, asthma, or respiratory distress. Additionally, integrating
ML-based cry analysis into bedside monitoring or mobile diagnostic devices would
enable healthcare providers to receive real-time alerts for atypical cry patterns, comple-
menting traditional clinical assessments. Beyond clinical facilities, ML-based cry ana-
lysis can also support parental education and telehealth applications, particularly for
ﬁrst-time parents or those in remote areas. When embedded in mobile health devices,
ML algorithms can provide parents with immediate feedback, promoting appropriate
caregiving responses.
However, several barriers may limit implementation in real-world settings. These
include the high cost of developing and maintaining advanced ML systems, the need
for well-labeled datasets, the need for validation across different clinical populations,
and the need for specialized training for healthcare providers to correctly interpret and
respond to system outputs. Additionally, disparities in access to technology across differ-
ent healthcare settings can pose signiﬁcant challenges. Therefore, effective clinical prac-
tice also necessitates training for healthcare providers and the development of technical
systems for the application of infant cry analysis.
Acknowledgments
The authors sincerely thank Professor Dr. Hyekyun Rhee and Professor Dr. Lorraine Olszewski
Walker for their invaluable guidance and support in elaborating this work.
ORCID iDs
Sudhathai Sirithepmontree
https://orcid.org/0009-0009-0495-1675
Nattasit Katchamat
https://orcid.org/0000-0002-8225-1756
Sasitara Nuampa
https://orcid.org/0000-0002-1325-8954
44
Science Progress 109(1)


---

Ethical considerations
This review was based on previously published literature available in public databases and did not involve
any human participants or the collection of new data; therefore, ethical approval was not required.
Author contributions
SS conceptualized the study and designed the review protocol. SS and NK performed the literature
search, screened articles, and extracted data. SN resolved any discrepancies. SS, NK, and SN con-
tributed to data analysis and interpretation. SS drafted and revised the manuscript. All authors have
read and approved the ﬁnal version of the manuscript.
Funding
The authors received no ﬁnancial support for the research, authorship, and/or publication of this
article.
Declaration of conﬂicting interests
The authors declared no potential conﬂicts of interest with respect to the research, authorship, and/
or publication of this article.
Supplemental material
Supplemental material for this article is available online.
References
1. Valdes MM, Reyes-Galaviz OF, Ortiz SDC, et al. Biosignal processing and classiﬁcation
using computational learning and intelligence. In: Analysis and processing of infant cry for
diagnosis purposes. London, UK: Academic Press, 2022.
2. Joshi VR, Srinivasan K, Vincent P, et al. A multistage heterogeneous stacking ensemble
model for augmented infant cry classiﬁcation. Front Public Health 2022; 10: 1–19. DOI:
10.3389/fpubh.2022.819865
3. Ashwini K, Vincent P, Srinivasan K, et al. Deep learning assisted neonatal cry classiﬁcation
via support vector machine models. Front Public Health 2021; 9: 670352.
4. Khalilzad Z, Hasasneh A and Tadj C. Newborn cry-based diagnostic system to distinguish
between sepsis and respiratory distress syndrome using combined acoustic features.
Diagnostics 2022; 12: 1–21.
5. Matikolaie FS and Tadj C. Machine learning-based cry diagnostic system for identifying sep-
tic newborns. J Voice 2024; 38: 963 e1–963 e14.
6. Kurth E, Kennedy HP, Zemp Stutz E, et al. Responding to a crying infant—you do not learn it
overnight: a phenomenological study. Midwifery 2014; 30: 742–749.
7. Shin H, Park YJ, Ryu H, et al. Maternal sensitivity: a concept analysis. J Adv Nurs 2008; 64:
304–314.
8. Petzoldt J, Wittchen HU, Einsle F, et al. Maternal anxiety versus depressive disorders: speciﬁc
relations to infants’ crying, feeding and sleeping problems. Child Care Health Dev 2015; 42:
231–245.
Sirithepmontree et al.
45


---

9. Oberlander TF and Rotem-Kohavi N. Post-partum depression and infant crying behaviour.
Crying behaviour. Encyclopedia on Early Childhood Development, 2017. University of
British Columbia.
10. Brand S, Furlano R, Sidler M, et al. Associations between infants’ crying, sleep and cortisol
secretion and mother’s sleep and well-being. Neuropsychobiology 2014; 69: 39–51.
11. Chang C-Y, Bhattacharya S, Vincent PMDR, et al. An efﬁcient classiﬁcation of neonates cry
using extreme gradient boosting-assisted grouped-support-vector network. J Healthc Eng
2021; 2021: 1–14.
12. Li F, Cui C and Hu Y. Classiﬁcation of infant crying sounds using SE-ResNet-transformer.
Sensors 2024; 24: 6575.
13. Lockhart-Bouron M, Anikin A, Pisanski K, et al. Infant cries convey both stable and dynamic
information about age and identity. Commun Psychol 2023; 1: 26.
14. Marler P. Social organization, communications and graded signals: the chimpanzee and the
gorilla. In: Growing points in ethology. Cambridge: Cambridge University Press, 1976.
15. Parga JJ, Lewin S, Lewis J, et al. Deﬁning and distinguishing infant behavioral states using
acoustic cry analysis: is colic painful? Pediat Res 2020; 87: 576–580.
16. Liang Y-C, Wijaya I, Yang M-T, et al. Deep learning for infant cry recognition. Int J Environ
Res Public Health 2022; 19: 6311.
17. Hammoud M, Getahun MN, Baldycheva A, et al. Machine learning-based infant crying inter-
pretation. Front Artif Intell 2024; 7: 1337356.
18. França RP, Borges Monteiro AC, Arthur R, et al. Trends in deep learning methodologies.
In: An overview of deep learning in big data, image, and signal processing in the modern
digital age. London, UK: Academic Press, 2021.
19. Sarker IH. Machine learning: algorithms, real-world applications and research directions. SN
Comput Sci 2021; 2: 60.
20. Jian Y, Pasquier M, Sagahyroon A, et al. A machine learning approach to predicting diabetes
complications. Healthcare 2021; 9: 1712.
21. Tesfaye SH, Seboka BT and Sisay D. Application of machine learning methods for predicting
childhood anaemia: analysis of Ethiopian Demographic Health Survey of 2016. PLoS One
2024; 19: e0300172.
22. Mukhopadhyay J, Saha B, Majumdar B, et al. An evaluation of human perception for neonatal
cry using a database of cry and underlying cause. In: Indian conference on medical informatics
and telemedicine, 2013, pp.64–67.
23. Zayed Y, Hasasneh A and Tadj C. Infant cry signal diagnostic system using deep learning and
fused features. Diagnostics 2023; 13: 1–22.
24. Rosales-Pérez A, Reyes-García CA, Gonzalez JA, et al. Classifying infant cry patterns by the
genetic selection of a fuzzy model. Biomed Signal Process Control 2015; 17: 38–46.
25. Mangold C, Zoretic S, Thallapureddy K, et al. Machine learning models for predicting neo-
natal mortality: a systematic review. Neonatology 2021; 118: 394–405.
26. McAdams RM, Kaur R, Sun Y, et al. Predicting clinical outcomes using artiﬁcial intelligence
and machine learning in neonatal intensive care units: a systematic review. J Perinatol 2022;
42: 1561–1575.
27. Shariﬁ-Heris Z, Laitala J, Airola A, et al. Machine learning approach for preterm birth predic-
tion using health records: systematic review. JMIR Med Inform 2022; 10: e33875.
46
Science Progress 109(1)


---

28. Bertini A, Salas R, Chabert S, et al. Using machine learning to predict complications in preg-
nancy: a systematic review. Front Bioeng Biotechnol 2021; 9: 1–16.
29. Page MJ, McKenzie JE, Bossuyt PM, et al. The PRISMA 2020 statement: an updated guide-
line for reporting systematic reviews. Br Med J 2021; 372: 1–9.
30. Whiting PF, Rutjes AWS, Westwood ME, et al. QUADAS-2: a revised tool for the quality
assessment of diagnostic accuracy studies. Ann Intern Med 2011; 155: 529–536.
31. Krauze AV, Zhuge Y, Zhao R, et al. AI-driven image analysis in central nervous system
tumors—traditional machine learning, deep learning and hybrid models. J Biotechnol
Biomed 2022; 5: 1–19.
32. Ludwig T, Richards JA, Coulter KK, et al. Automated detection of infant crying and fussing
for clinical applications. J Pediatr Gastroenterol Nutr 2018; 66: 71.
33. Saraswathy J, Hariharan M, Khairunizam W, et al. Time-frequency analysis-based method for
application of infant cry classiﬁcation. Int J Med Eng Inform 2020; 12: 119–134.
34. Zhang K, Ting HN and Choo YM. Baby cry recognition based on WOA-VMD and an
improved Dempster–Shafer evidence theory. Comput Methods Programs Biomed 2024;
245: 1–15.
35. Laguna A, Pusil S, Bazán À, et al. Multi-modal analysis of infant cry types characterization:
acoustics, body language and brain signals. Comput Biol Med 2023; 167: 1–10.
36. Matikolaie FS and Tadj C. On the use of long-term features in a newborn cry diagnostic sys-
tem. Biomed Signal Process Control 2020; 59: 1–9.
37. Abbaskhah A, Sedighi H and Marvi H. Infant cry classiﬁcation by MFCC feature extraction
with MLP and CNN structures. Biomed Signal Process Control 2023; 86: 1–11.
38. Patil HA, Kachhi A and Patil AT. CQT-based cepstral features for classiﬁcation of normal vs.
pathological infant cry. IEEE Trans Audio Speech Lang Process 2024; 32: 4713–4726.
39. Zhang K, Ting H-N and Choo Y-M. Baby cry recognition by BCRNet using transfer learning
and deep feature fusion. IEEE Access 2023; 11: 126251–126262.
40. Aggarwal G, Jhajharia K, Izhar J, et al. A machine learning approach to classify biomedical
acoustic features for baby cries. J Voice 2025; 39: 1446–1455.
41. Liang YC, Wijaya I, Yang MT, et al. Deep learning for infant cry recognition. Int J Environ
Res Public Health 2022; 19: 1–10.
42. Valani B. Donate-a-cry-corpus-features-dataset. Kaggle. https://www.kaggle.com/datasets/
bhoomikavalani/donateacrycorpusfeaturesdataset/data.
43. Busquet F, Efthymiou F and Hildebrand C. Voice analytics in the wild: validity and predictive
accuracy of common audio-recording devices. Behav Res Methods 2024; 56: 2114–2134.
44. Reyes-Galaviz OF, Cano-Ortiz SD and Reyes-García CA. Evolutionary-neural system to clas-
sify infant cry units for pathologies identiﬁcation in recently born babies. In: Presented at:
2008 Seventh Mexican international conference on artiﬁcial intelligence, 2008.
45. Maghﬁra TN, Basaruddin T and Krisnadhi A. Infant cry classiﬁcation using CNN–RNN. J
Phys Conf Ser 2020; 1528: 012019.
46. Dunstan Baby Language. https://www.dunstanbaby.com/.
47. Aliferis C and Simon G. Overﬁtting, underﬁtting and general model overconﬁdence and
under-performance pitfalls and best practices in machine learning and AI. Cham,
Switzerland: Springer, 2024.
Sirithepmontree et al.
47


---

48. Yao X, Micheletti M, Johnson M, et al. Infant crying detection in real-world environments.
Proc IEEE Int Conf Acoust Speech Signal Process 2022; 2022: 131–135.
49. Jebarani PE, Umadevi N, Dang H, et al. A novel hybrid K-means and GMM machine learning
model for breast cancer detection. IEEE Access 2021; 9: 146153–146162.
50. KhlaiﬁH, Istrate D, Demongeot J, et al. Swallowing sound recognition at home using GMM.
IRBM 2018; 39: 407–412.
51. Sen I, Saraclar M and Kahya Y. A comparison of SVM and GMM-based classiﬁer conﬁgura-
tions for diagnostic classiﬁcation of pulmonary sounds. IEEE Trans Biomed Eng 2015; 62:
1768–1776.
52. Ji C, Mudiyanselage T, Gao Y, et al. A review of infant cry analysis and classiﬁcation.
EURASIP J Audio Speech Music Process 2021; 2021: 1–17.
53. Mekhﬁoui M, Fadel W, Hammouch FE, et al. Development of a baby cry identiﬁcation
system using a raspberry pi-based embedded system and machine learning. Technologies
2025; 13: 1–13.
54. Cornec C, Mathevon N, Pisanski K, et al. Human infant cries communicate distress and elicit
sex stereotypes: cross cultural evidence. Evol Hum Behav 2024; 45: 48–57.
55. Gustafson GE, Sanborn SM, Lin HC, et al. Newborns’ cries are unique to individuals (but not
to language environment). Infancy 2017; 22: 736–747.
48
Science Progress 109(1)


---
*Full text extracted from PDF for MemoVoice V3 algorithm training.*
